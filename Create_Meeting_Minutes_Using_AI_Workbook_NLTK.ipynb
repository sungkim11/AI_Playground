{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhO19mzy8Ck5/2M/LJXzYw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sungkim11/ai-playground/blob/main/Create_Meeting_Minutes_Using_AI_Workbook_NLTK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create a Meeting Minute using OpenAI's GPT-3 from both Microsoft Team's Meeting Transcript or Zoom's Meeting Transcript (NLTK)"
      ],
      "metadata": {
        "id": "vC0t_IHQgV6-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is my endeavor to replicate upcoming Microsoft Team Premium feature to create meeting notes using AI."
      ],
      "metadata": {
        "id": "N7R-tsFJgr7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Prerequisites"
      ],
      "metadata": {
        "id": "4b_S-B5jg7f2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following are prerequisites for this tutorial:\n",
        "\n",
        "- Python Package: openai\n",
        "- Python Package: nltk (Natural Language Toolkit)"
      ],
      "metadata": {
        "id": "DfTwEED_g_kb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.1. Python Packages"
      ],
      "metadata": {
        "id": "hEIroo2BhEzH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####1.1.1. Install Python Packages"
      ],
      "metadata": {
        "id": "z8G98yU0z8y_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uNn49xIzMq7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a55f3dd6-6dc0-44dc-f419-6f3e23a21da3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile requirements.txt\n",
        "openai\n",
        "nltk\n",
        "re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "fdJwUNoszSIp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3990e9d-9857-41ee-8577-c1d1a11050ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (0.26.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai->-r requirements.txt (line 1)) (4.64.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from openai->-r requirements.txt (line 1)) (3.8.3)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai->-r requirements.txt (line 1)) (2.25.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk->-r requirements.txt (line 2)) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->-r requirements.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->-r requirements.txt (line 2)) (7.1.2)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai->-r requirements.txt (line 1)) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai->-r requirements.txt (line 1)) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai->-r requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai->-r requirements.txt (line 1)) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai->-r requirements.txt (line 1)) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai->-r requirements.txt (line 1)) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai->-r requirements.txt (line 1)) (2.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai->-r requirements.txt (line 1)) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai->-r requirements.txt (line 1)) (1.8.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Code"
      ],
      "metadata": {
        "id": "dzLhnP--hOxp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colab code to prettify text output."
      ],
      "metadata": {
        "id": "lGFFGcY1tasJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Ow3tBDBfseRE",
        "outputId": "6ae158d9-63b4-4b28-9e91-b5e8b94e6670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.1. Import Python Packages"
      ],
      "metadata": {
        "id": "WmRPmprK0GM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import platform\n",
        "import os\n",
        "\n",
        "import openai\n",
        "\n",
        "import re\n",
        "from os.path import splitext, exists\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "print('Python: ', platform.python_version())\n",
        "print('re: ', re.__version__)\n",
        "print('nltk: ', nltk.__version__)"
      ],
      "metadata": {
        "id": "0Zs3zeEy0HXX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23901a37-2f84-4724-ee6b-e10d09866834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python:  3.8.10\n",
            "re:  2.2.1\n",
            "nltk:  3.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.2. Mount Storage - Google Drive"
      ],
      "metadata": {
        "id": "_5EJ0NJHzmxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Tx1d61zFzkMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9a9aa06-d322-47c5-e088-8166b382cba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.3. Clean Meeting Transcript from either Microsoft Team or Zoom, encoded as WEBVTT file."
      ],
      "metadata": {
        "id": "qj6-FtO2zsb8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The meeting transcript is encoded as follows:\n",
        "\n",
        "    WEBVTT\n",
        "    \n",
        "    03951482-18bc-403b-9a4f-9d2699587f03/65-1\n",
        "    00:00:08.885 --> 00:00:13.589\n",
        "    transcription making sure that\n",
        "    the transcription does work. Yep"
      ],
      "metadata": {
        "id": "jvuyPQvdiTq1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is not usually problem with ChatGPT, but OpenAI GPT-3 API charges by a token and we want to minimize the number of tokens sending to it. We will need to remove all lines that is not a transcript."
      ],
      "metadata": {
        "id": "dW6bAm4WjRTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These two functions clean up .vtt file and then produce a clean text file with the same filename with an extension of .txt."
      ],
      "metadata": {
        "id": "5I6qHWX9kJb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_webvtt(filepath: str) -> str:\n",
        "    \"\"\"Clean up the content of a subtitle file (vtt) to a string\n",
        "\n",
        "    Args:\n",
        "        filepath (str): path to vtt file\n",
        "\n",
        "    Returns:\n",
        "        str: clean content\n",
        "    \"\"\"\n",
        "    # read file content\n",
        "    with open(filepath, \"r\", encoding=\"utf-8\") as fp:\n",
        "        content = fp.read()\n",
        "\n",
        "    # remove header & empty lines\n",
        "    lines = [line.strip() for line in content.split(\"\\n\") if line.strip()]\n",
        "    lines = lines[1:] if lines[0].upper() == \"WEBVTT\" else lines\n",
        "\n",
        "    # remove indexes\n",
        "    lines = [lines[i] for i in range(len(lines)) if not lines[i].isdigit()]\n",
        "\n",
        "    # remove tcode\n",
        "    #pattern = re.compile(r'^[0-9:.]{12} --> [0-9:.]{12}')\n",
        "    pattern = r'[a-f\\d]{8}-[a-f\\d]{4}-[a-f\\d]{4}-[a-f\\d]{4}-[a-f\\d]{12}\\/\\d+-\\d'\n",
        "    lines = [lines[i] for i in range(len(lines))\n",
        "             if not re.match(pattern, lines[i])]\n",
        "\n",
        "    # remove timestamps\n",
        "    pattern = r\"^\\d{2}:\\d{2}:\\d{2}.\\d{3}.*\\d{2}:\\d{2}:\\d{2}.\\d{3}$\"\n",
        "    lines = [lines[i] for i in range(len(lines))\n",
        "             if not re.match(pattern, lines[i])]\n",
        "\n",
        "    content = \" \".join(lines)\n",
        "\n",
        "    # remove duplicate spaces\n",
        "    pattern = r\"\\s+\"\n",
        "    content = re.sub(pattern, r\" \", content)\n",
        "\n",
        "    # add space after punctuation marks if it doesn't exist\n",
        "    pattern = r\"([\\.!?])(\\w)\"\n",
        "    content = re.sub(pattern, r\"\\1 \\2\", content)\n",
        "\n",
        "    return content\n",
        "\n",
        "\n",
        "def vtt_to_clean_file(file_in: str, file_out=None, **kwargs) -> str:\n",
        "    \"\"\"Save clean content of a subtitle file to text file\n",
        "\n",
        "    Args:\n",
        "        file_in (str): path to vtt file\n",
        "        file_out (None, optional): path to text file\n",
        "        **kwargs (optional): arguments for other parameters\n",
        "            - no_message (bool): do not show message of result.\n",
        "                                 Default is False\n",
        "\n",
        "    Returns:\n",
        "        str: path to text file\n",
        "    \"\"\"\n",
        "    # set default values\n",
        "    no_message = kwargs.get(\"no_message\", False)\n",
        "    if not file_out:\n",
        "        filename = splitext(file_in)[0]\n",
        "        file_out = \"%s.txt\" % filename\n",
        "        i = 0\n",
        "        while exists(file_out):\n",
        "            i += 1\n",
        "            file_out = \"%s_%s.txt\" % (filename, i)\n",
        "\n",
        "    content = clean_webvtt(file_in)\n",
        "    with open(file_out, \"w+\", encoding=\"utf-8\") as fp:\n",
        "        fp.write(content)\n",
        "    if not no_message:\n",
        "        print(\"clean content is written to file: %s\" % file_out)\n",
        "\n",
        "    return file_out"
      ],
      "metadata": {
        "id": "d1T3XitJ1Z58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"/content/drive/MyDrive/Colab Notebooks/minutes/data/Round_22_Online_Kickoff_Meeting.vtt\"\n",
        "\n",
        "vtt_to_clean_file(filepath)"
      ],
      "metadata": {
        "id": "ZHOtHSt60g91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1b70ce9c-5d91-4b1c-fd6d-2ba2be93f2b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clean content is written to file: /content/drive/MyDrive/Colab Notebooks/minutes/data/Round_22_Online_Kickoff_Meeting.txt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/minutes/data/Round_22_Online_Kickoff_Meeting.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.4. Count the Number of Tokens"
      ],
      "metadata": {
        "id": "FC-sdhOqk7Qr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpenAI GPT-3 is limited by 4,001 tokens it can handle per request which includes both request (i.e., prompt) and response. We will be analyzing how many tokens are in this meeting transcript."
      ],
      "metadata": {
        "id": "HgPybdZ1kqTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_tokens(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        text = f.read()\n",
        "        \n",
        "    tokens = word_tokenize(text)\n",
        "    num_tokens = len(tokens)\n",
        "    return num_tokens"
      ],
      "metadata": {
        "id": "GokXzz3yk-YJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"/content/drive/MyDrive/Colab Notebooks/minutes/data/Round_22_Online_Kickoff_Meeting.txt\"\n",
        "token_count = count_tokens(filename)\n",
        "print(f\"Number of tokens: {token_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iOYMH0vltT5",
        "outputId": "8053d293-9149-42af-a7b2-5714ae3a0f96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tokens: 17045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.5. Break up the Meeting Transcript into chunks of 2000 tokens with an overlap of 100 tokens"
      ],
      "metadata": {
        "id": "1oeA8ivUmql8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be breaking up the Meeting Transcript into chunks of 2,000 tokens with an overlapping 100 tokens to ensure any information is not lost from breaking up the meeting transcript."
      ],
      "metadata": {
        "id": "JNGJroB_mvCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def break_up_file(tokens, chunk_size, overlap_size):\n",
        "    if len(tokens) <= chunk_size:\n",
        "        yield tokens\n",
        "    else:\n",
        "        chunk = tokens[:chunk_size]\n",
        "        yield chunk\n",
        "        yield from break_up_file(tokens[chunk_size-overlap_size:], chunk_size, overlap_size)\n",
        "\n",
        "def break_up_file_to_chunks(filename, chunk_size=2000, overlap_size=100):\n",
        "    with open(filename, 'r') as f:\n",
        "        text = f.read()\n",
        "    tokens = word_tokenize(text)\n",
        "    return list(break_up_file(tokens, chunk_size, overlap_size))"
      ],
      "metadata": {
        "id": "sTSrIXWqmp5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"/content/drive/MyDrive/Colab Notebooks/minutes/data/Round_22_Online_Kickoff_Meeting.txt\"\n",
        "\n",
        "chunks = break_up_file_to_chunks(filename)\n",
        "for i, chunk in enumerate(chunks):\n",
        "    print(f\"Chunk {i}: {len(chunk)} tokens\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMQ4XMAzm05T",
        "outputId": "48e30541-f294-4a3c-8917-fae437686fc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 0: 2000 tokens\n",
            "Chunk 1: 2000 tokens\n",
            "Chunk 2: 2000 tokens\n",
            "Chunk 3: 2000 tokens\n",
            "Chunk 4: 2000 tokens\n",
            "Chunk 5: 2000 tokens\n",
            "Chunk 6: 2000 tokens\n",
            "Chunk 7: 2000 tokens\n",
            "Chunk 8: 1845 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.6. Validate the break up the Meeting Transcript into chunks of 2000 tokens with an overlap of 100 tokens"
      ],
      "metadata": {
        "id": "rdKOVSLcnH0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(chunks[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGd43PG3nvie",
        "outputId": "ec12d8f6-4db9-4a23-8246-13edbb07312a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hi', 'everyone', 'I', 'am', 'about', 'to', 'start', 'the', 'recording', 'and', 'the', 'transcription', 'making', 'sure', 'that', 'the', 'transcription', 'does', 'work', '.', 'Yep', 'it', 'does', '.', 'Excellent', '.', 'OK', ',', 'well', ',', 'welcome', 'to', 'the', 'kickoff', 'meeting', 'and', 'congratulations', 'to', 'everybody', 'in', 'here', 'for', 'being', 'a', 'awarded', 'around', '22', 'grants', '.', 'Round', '22', 'was', 'a', 'heck', 'of', 'an', 'application', 'round', '.', 'There', 'were', 'many', 'good', 'applications', '.', 'We', 'had', 'to', 'turn', 'down', 'quite', 'a', 'few', 'and', 'we', 'really', 'hope', 'that', 'those', 'who', 'were', 'turned', 'down', 'will', 'revise', 'and', 'resubmit', 'because', 'there', 'were', 'just', 'so', 'many', 'great', 'ideas', 'and', \"y'all\", 'were', 'at', 'the', 'top', '.', 'Of', 'the', 'of', 'the', 'list', ',', 'so', 'it', \"'s\", 'it', \"'s\", 'excellent', 'to', 'see', 'you', 'all', 'here', '.', 'And', 'today', 'we', \"'re\", 'just', 'going', 'to', 'connect', 'with', 'each', 'other', 'a', 'little', 'bit', '.', 'I', \"'m\", 'gon', 'na', 'take', 'you', 'through', 'some', 'of', 'the', 'key', 'ALG', 'stuff', 'that', 'we', \"'ve\", 'got', 'to', 'offer', '.', 'First', ',', 'we', \"'ll\", 'do', 'some', 'introductions', ',', 'then', 'we', 'will', 'talk', 'about', 'the', 'nitty', 'gritty', ',', 'the', 'grant', 'procedure', ',', 'stuff', 'that', 'everybody', 'needs', 'to', 'know', 'in', 'order', 'for', 'payments', 'to', 'go', 'forward', 'and', 'for', 'signatures', 'to', 'go', 'through', '.', 'Ah', ',', 'yeah', '.', 'And', 'uh', ',', 'Yep', ',', 'hygiene', 'greetings', 'from', 'KSU', 'representing', 'herself', 'and', 'the', 'amazing', 'Tammy', 'Powell', ',', 'of', 'course', '.', 'And', 'Amelia', ',', 'hi', 'everyone', '.', 'Also', 'from', 'KSU', 'with', 'Gene', 'excellent', '.', 'We', \"'ll\", 'do', 'some', 'introductions', 'very', 'soon', 'too', '.', 'So', 'first', 'I', \"'m\", 'going', 'to', 'take', 'you', 'through', 'a', 'quick', 'look', 'of', 'what', 'we', 'have', 'here', 'at', 'ALG', '.', 'So', 'I', \"'m\", 'going', 'to', 'go', 'share', 'my', 'window', 'here', 'if', 'the', 'Windows', 'decide', 'that', 'they', 'want', 'to', 'do', 'something', ',', 'here', 'we', 'go', 'perfect', '.', 'OK', '.', 'I', \"'m\", 'going', 'to', 'blow', 'this', 'up', 'a', 'little', 'bit', ',', 'make', 'sure', 'that', 'everybody', 'can', 'see', 'it', '.', 'I', \"'m\", 'going', 'to', 'zoom', 'in', '.', 'So', 'this', 'is', 'not', 'usually', 'how', 'the', 'site', 'looks', ',', 'but', 'I', 'am', 'zooming', 'in', 'so', 'that', 'everyone', 'can', 'see', '.', 'This', 'is', 'the', 'affordable', 'Learning', 'Georgia', 'website', '.', 'If', 'you', 'apply', 'for', 'a', 'grant', ',', 'you', 'probably', 'have', 'seen', 'this', 'before', ',', 'but', 'if', 'you', 'have', \"n't\", ',', 'this', 'is', 'a', 'kind', 'of', 'the', 'hub', 'for', 'everything', 'that', 'we', 'have', 'to', 'offer', '.', 'It', \"'s\", 'out', 'affordable', ',', 'learninggeorgia', '.', 'org', 'kind', 'of', 'a', 'long', 'URL', ',', 'but', 'it', 'is', 'at', 'least', 'the', 'exact', 'name', 'of', 'what', 'we', 'have', '.', 'We', 'have', 'three', 'big', 'buttons', 'down', 'here', 'that', 'direct', 'folks', 'to', 'the', 'most', 'important', 'places', 'that', 'they', 'wan', 'na', 'go', '.', 'If', 'you', \"'re\", 'looking', 'for', 'the', 'OER', 'that', 'we', \"'re\", 'created', 'through', 'this', 'program', 'and', 'by', 'doing', 'the', 'asynchronous', 'training', ',', 'you', 'should', 'know', 'what', 'OER', 'is', 'all', 'about', 'open', 'educational', 'resources', '.', 'They', \"'re\", 'open', ',', 'licensed', '.', 'You', 'can', 'repurpose', 'them', '.', 'You', 'can', 'revise', 'them', '.', 'The', 'ones', 'that', 'Georgia', 'folks', 'have', 'created', ',', 'you', 'can', 'go', 'into', 'open', 'educational', 'resources', 'and', 'you', \"'ll\", 'find', 'the', 'two', 'places', 'for', 'them', 'that', 'I', 'will', 'show', 'you', 'a', 'little', 'bit', 'later', '.', 'Statistics', ',', 'research', 'and', 'reports', '.', 'If', 'people', 'are', 'looking', 'for', 'data', 'and', 'this', 'is', 'especially', 'administrators', ',', 'champions', 'who', 'want', 'to', 'do', 'a', 'report', 'for', 'their', 'institution', ',', 'even', 'media', 'outlets', 'when', 'they', 'want', 'to', 'report', 'on', 'what', 'Georgia', 'is', 'doing', ',', 'that', 'this', 'is', 'going', 'to', 'be', 'the', 'place', 'where', 'you', 'want', 'to', 'go', 'and', 'then', 'there', \"'s\", 'affordable', 'materials', 'grants', '.', 'This', 'has', 'the', 'entire', 'history', 'of', 'our', 'grant', 'program', 'all', 'the', 'way', 'back', 'to', 'around', '1:00', 'and', 'it', 'has', 'the', 'hub', 'for', '.', 'Everything', 'that', 'you', \"'ll\", 'need', 'to', 'know', 'about', 'the', 'grant', 'procedures', 'and', 'that', 'is', 'in', 'here', ',', 'current', 'grantees', ',', 'reports', 'and', 'deadlines', ',', 'this', 'is', 'a', 'super', 'helpful', ',', 'super', 'important', 'link', 'and', 'we', \"'ll\", 'talk', 'about', 'it', 'a', 'couple', 'of', 'times', 'today', '.', 'This', 'is', 'the', 'ALG', 'grants', 'equivalence', 'of', 'the', 'syllabus', 'that', 'you', 'have', 'to', 'keep', 'pointing', 'everyone', 'towards', 'because', 'that', \"'s\", 'where', 'everything', 'is', '.', 'Here', 'we', \"'ve\", 'got', 'every', 'deadline', 'by', 'semester', '.', 'We', 'even', 'have', 'the', 'old', 'ones', 'of', 'summer', '2022', '.', 'Paul', 'reporting', 'deadline', 'is', 'December', '19th', 'as', 'we', 'will', 'explain', ',', 'you', 'do', 'not', 'have', 'to', 'worry', 'about', 'this', 'one', 'at', 'all', 'because', 'it', 'is', 'coming', 'up', 'way', 'too', 'soon', ',', 'then', 'spring', ',', 'then', 'summer', ',', 'then', 'fall', '.', 'There', 'will', 'always', 'be', 'here', 'whenever', 'you', 'want', 'to', 'check', 'on', 'it', '.', 'Umm', ',', 'there', \"'s\", 'all', 'the', 'ways', 'that', 'you', 'can', 'submit', 'a', 'report', 'including', 'our', 'templates', 'and', 'our', 'forms', 'to', 'submit', 'them', '.', 'On', 'the', 'reporting', 'guidelines', ',', 'some', 'platforms', 'and', 'ways', 'to', 'host', 'stuff', ',', 'some', 'research', 'resources', 'in', 'case', 'you', \"'re\", 'interested', 'in', 'doing', 'some', 'research', 'as', 'a', 'part', 'of', 'this', ',', 'and', 'then', 'the', 'online', 'kickoff', 'training', '.', 'So', 'we', 'will', 'have', 'the', 'most', 'recent', 'kickoff', ',', 'this', 'one', 'right', 'on', 'YouTube', '.', 'So', 'if', 'you', \"'re\", 'watching', 'that', 'right', 'now', ',', 'hello', ',', 'how', 'are', 'you', '?', 'The', 'presentation', 'slides', 'are', 'going', 'to', 'be', 'here', 'as', 'well', 'and', 'there', \"'s\", 'a', 'little', 'thing', 'about', 'the', 'ALG', 'grantees', 'listserv', '.', 'I', 'just', 'recently', 'added', 'all', 'of', 'you', 'to', 'that', 'listserv', '.', 'If', 'you', 'were', 'a', 'grantee', 'in', 'a', 'previous', 'round', ',', 'then', 'you', 'were', 'already', 'there', '.', 'But', 'if', 'you', 'are', 'a', 'new', 'grantee', 'now', ',', 'you', 'have', '.', 'More', 'of', 'a', '.', 'Way', 'for', 'us', 'to', 'connect', 'with', 'you', 'about', 'reporting', 'deadlines', 'and', 'such', '.', 'OK', ',', 'so', 'this', 'is', 'a', 'really', 'important', 'page', 'and', 'we', 'will', 'be', 'directing', 'you', 'towards', 'it', 'a', 'couple', 'of', 'times', '.', 'I', 'heavily', 'recommend', 'that', 'if', 'you', 'are', 'a', 'project', 'lead', ',', 'bookmark', 'this', 'page', '.', 'It', 'is', 'a', 'place', 'to', 'go', '.', 'Now', 'we', 'have', 'two', 'big', 'homes', 'for', 'OER', '.', 'The', 'stuff', 'that', 'has', 'been', 'created', 'as', 'a', 'part', 'of', 'these', 'grants', '.', 'This', 'is', 'Galileo', 'open', 'learning', 'materials', '.', 'It', 'was', 'our', 'first', 'ever', 'repository', '.', 'We', 'had', 'our', 'grants', 'a', 'couple', 'of', 'years', 'before', 'we', 'got', 'this', 'repository', '.', 'This', 'place', 'to', 'store', 'open', 'materials', 'that', 'were', 'created', 'during', 'the', 'grants', '.', 'We', 'thought', 'that', 'there', 'were', 'so', 'much', 'great', 'open', 'material', 'out', 'there', 'that', 'we', 'would', \"n't\", 'have', 'to', 'have', 'a', 'place', 'to', 'host', 'our', 'own', 'OER', '.', 'It', \"'s\", 'all', 'out', 'there', '.', 'Just', 'go', 'ahead', 'and', 'use', 'it', '.', 'Well', ',', 'that', 'was', 'not', 'the', 'case', 'at', 'all', '.', 'People', 'created', 'so', 'much', 'good', 'stuff', 'that', 'we', 'needed', 'a', 'place', 'to', 'host', 'it', '.', 'O', 'this', 'is', 'what', 'we', 'started', 'with', '.', 'This', 'is', 'a', 'repository', 'in', 'the', 'old', 'sense', 'of', 'the', 'word', '.', 'It', \"'s\", 'got', 'entries', 'in', 'here', 'that', 'look', 'a', 'lot', 'like', 'any', 'library', 'resource', '.', 'You', 'would', 'go', 'to', '.', 'You', \"'ve\", 'got', 'the', 'author', 'fields', 'and', 'you', \"'ve\", 'got', 'the', 'description', 'fields', '.', 'We', \"'ve\", 'got', 'a', 'few', 'custom', 'fields', 'in', 'here', 'for', 'course', '.', 'Title', 'and', 'course', 'number', ',', 'the', 'Creative', 'Commons', 'license', 'has', 'built', ',', 'right', '?', 'And', 'here', \"'s\", 'where', 'it', 'was', 'published', '.', 'All', 'of', 'that', 'stuff', '.', 'And', 'you', 'can', 'download', 'the', 'full', 'text', 'of', 'this', 'particular', 'one', '.', 'These', 'guys', 'had', 'a', 'word', 'version', 'and', 'some', 'lecture', 'slides', 'and', 'some', 'primary', 'source', 'exercises', 'there', '.', 'That', \"'s\", 'pretty', 'cool', '.', 'You', 'can', 'search', 'in', 'just', 'this', 'collection', 'and', 'the', 'whole', 'repository', 'or', 'across', 'every', 'repository', ',', 'which', 'is', 'a', 'little', 'bit', '.', 'More', 'you', 'will', 'see', 'here', 'in', 'the', 'kind', 'of', 'analytics', 'section', 'down', 'here', 'that', 'we', 'have', 'had', 'over', '2,000,000', 'total', 'downloads', 'since', '2016', 'and', 'just', 'about', 'anywhere', 'where', 'English', 'is', 'a', 'primary', 'or', 'second', 'language', '.', 'You', 'will', 'see', 'some', 'usage', '.', 'So', 'you', 'just', 'saw', 'one', 'in', 'Uttar', 'Pradesh', 'alongside', 'Iowa', '.', 'So', 'it', 'really', 'interesting', 'usage', 'going', 'on', '.', 'You', 'can', 'also', 'see', 'the', 'top', '10', 'downloads', 'of', 'all', 'time', '.', 'Educational', 'learning', 'theories', 'is', 'a', 'really', 'big', 'one', 'with', '389', '.', '1000', 'downloads', 'so', 'very', 'cool', ',', 'but', 'all', 'of', 'these', 'of', 'course', 'are', 'static', 'files', '.', 'We', 'wanted', 'a', 'way', 'to', 'make', 'these', 'open', 'resources', 'both', 'still', 'accessible', 'for', 'faculty', 'to', 'create', 'and', 'more', 'interactive', 'and', 'accessible', 'for', 'students', 'to', 'use', '.', 'O', 'we', 'partnered', 'with', 'Manifold', 'in', '2020', ',', 'manifold', 'is', 'a', 'new', 'project', '.', 'It', 'came', 'out', 'of', 'the', 'University', 'of', 'Minnesota', 'and', 'some', 'partnerships', 'with', 'the', 'City', 'University', 'of', 'New', 'York', 'or', 'CUNY', 'system', '.', 'And', 'this', 'place', 'is', 'a', 'place', 'where', 'you', 'could', 'take', 'static', 'files', 'like', 'word', 'documents', 'and', 'epubs', 'and', 'convert', 'them', 'over', 'into', 'texts', 'that', 'are', 'a', 'lot', 'more', 'interesting', '.', 'So', 'for', 'example', ',', 'here', 'is', 'Latinx', 'media', '.', 'And', 'I', \"'ll\", 'I', \"'ll\", 'go', 'back', 'to', 'the', 'project', 'home', 'to', 'show', 'you', 'what', 'this', 'looks', 'like', '.', 'We', \"'ve\", 'got', 'the', 'grant', 'documentation', 'over', 'here', 'because', 'this', 'was', 'created', 'around', '19', '.', 'We', \"'ve\", 'got', 'the', 'source', 'document', 'right', 'here', 'and', 'we', \"'ve\", 'got', 'the', 'start', 'reading', 'button', '.', 'If', 'I', 'hit', 'that', ',', 'I', 'go', 'right', 'to', 'the', 'introduction', '.', 'And', 'because', 'this', 'was', 'originally', 'a', 'Word', 'document', 'that', 'had', 'header', 'ones', 'and', 'header', 'twos', ',', 'we', 'have', 'chapters', 'and', 'subchapters', 'that', 'arise', 'from', 'that', 'structure', '.', 'So', 'not', 'only', 'does', 'structured', 'text', 'with', 'headers', ',', 'which', 'you', 'just', 'do', 'by', 'using', 'the', 'styles', 'in', 'Word', ',', 'not', 'only', 'does', 'that', 'make', 'it', 'more', 'accessible', 'to', 'screen', 'readers', ',', 'but', 'it', 'also', 'makes', 'it', 'way', 'more', 'cool', 'when', 'you', 'can', 'bring', 'it', 'over', 'into', 'manifold', '.', 'So', 'I', \"'ll\", 'go', 'over', 'to', 'the', 'second', 'chapter', 'of', 'this', 'unit', '.', 'And', 'here', 'we', 'are', '.', 'You', \"'ve\", 'got', 'live', 'links', '.', 'I', 'can', 'go', 'up', 'here', '.', 'And', 'if', 'there', 'were', 'a', 'lot', 'of', 'highlights', ',', 'I', 'could', 'turn', 'those', 'off', 'or', 'annotations', '.', 'The', 'public', 'can', 'do', 'this', '.', 'You', 'can', 'do', 'these', 'on', 'your', 'own', 'and', 'have', 'them', 'private', '.', 'If', 'you', 'wan', 'na', 'create', 'an', 'accounts', ',', 'you', 'can', 'even', 'create', 'a', 'group', 'like', 'your', 'entire', 'class', 'and', 'have', 'everybody', 'annotate', 'and', 'highlight', 'together', '.', 'You', 'can', 'change', 'things', 'from', 'Sarah', 'to', 'Sanserif', '.', 'You', 'can', 'and', 'large', 'the', 'fonts', '.', 'You', 'can', 'bring', 'it', 'back', 'down', '.', 'You', 'can', 'turn', 'on', 'dark', 'mode', 'or', 'light', 'mode', '.', 'You', 'can', 'close', 'the', 'margins', 'up', 'a', 'little', 'bit', 'or', 'expand', 'them', '.', 'You', 'can', 'bring', 'everything', 'back', 'to', 'default', ',', 'but', 'let', \"'s\", 'say', 'that', 'I', 'wanted', 'any', 'mention', 'of', 'television', 'because', 'I', \"'m\", 'seeing', 'television', 'right', 'here', 'on', 'this', 'screen', 'and', 'I', 'wan', 'na', 'search', 'within', 'the', 'text', '.', 'Well', 'then', 'I', 'can', 'find', 'exactly', 'where', 'television', 'is', 'mentioned', 'throughout', 'all', 'of', 'this', 'Latinx', 'media', 'text', '.', 'What', 'I', 'also', 'can', 'do', 'is', 'go', 'all', 'the', 'way', 'back', 'to', 'the', 'home', 'page', 'and', 'search', 'for', 'television', ',', 'and', 'if', 'I', 'do', 'that', 'here', ',', 'I', \"'m\", 'gon', 'na', 'find', 'every', 'mention', 'of', 'television', ',', 'even', 'in', 'the', 'annotations', ',', 'just', 'in', 'case', 'somebody', 'wanted', 'to', 'mention', 'it', '.', 'So', 'here', \"'s\", 'some', 'in', 'not', 'just', 'Latinx', 'media', ',', 'but', 'also', 'annotations', '.', 'And', 'in', 'the', 'film', 'appreciation', 'text', ',', 'some', 'that', 'are', 'in', 'a', 'Spanish', 'instructional', 'text', '.', 'Over', 'in', 'a', 'theater', 'chapter', '.', 'Yeah', '.', 'So', 'you', 'you', 'can', 'look', 'across', 'all', 'of', 'these', 'open', 'textbooks', 'at', 'once', ',', 'too', '.', 'So', 'we', 'will', 'work', 'with', 'you', 'on', 'getting', 'any', 'materials', 'that', 'you', \"'ve\", 'created', 'into', 'an', 'instance', 'of', 'manifold', '.', 'If', 'they', \"'re\", 'just', 'ancillary', 'materials', 'that', 'you', 'can', 'download', ',', 'we', \"'ll\", 'put', 'them', 'up', 'for', 'download', '.', 'If', 'you', \"'re\", 'creating', 'an', 'entirely', 'new', 'open', 'textbook', ',', 'then', 'we', \"'ll\", 'help', 'you', 'in', 'getting', 'this', 'into', 'manifold', 'in', 'a', 'really', 'cool', 'way', '.', 'We', 'even', 'have', 'some', 'training', 'resources', 'in', 'here', ',', 'including', 'a', 'champions', 'welcome', 'training', 'and', 'kickoff', 'training', ',', 'and', 'all', 'of', 'this', '.', 'These', 'are', 'entries', 'here', 'and', '.', 'You', 'know', ',', 'a', 'few', 'folks', 'from', 'Kennesaw', ',', 'including', 'a', 'few', 'that', 'are', 'here', 'today', ',', 'created', 'a', 'student', 'success', 'workshop', 'that', 'we', 'host', 'right', 'here', 'on', 'Open', 'ALG', 'as', 'well', '.', 'So', 'it', \"'s\", 'it', \"'s\", 'exciting']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chunks[0][-100:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpkKJOqeJjx-",
        "outputId": "beacff79-2be1-4960-ad73-bfbbb4b78629"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['put', 'them', 'up', 'for', 'download', '.', 'If', 'you', \"'re\", 'creating', 'an', 'entirely', 'new', 'open', 'textbook', ',', 'then', 'we', \"'ll\", 'help', 'you', 'in', 'getting', 'this', 'into', 'manifold', 'in', 'a', 'really', 'cool', 'way', '.', 'We', 'even', 'have', 'some', 'training', 'resources', 'in', 'here', ',', 'including', 'a', 'champions', 'welcome', 'training', 'and', 'kickoff', 'training', ',', 'and', 'all', 'of', 'this', '.', 'These', 'are', 'entries', 'here', 'and', '.', 'You', 'know', ',', 'a', 'few', 'folks', 'from', 'Kennesaw', ',', 'including', 'a', 'few', 'that', 'are', 'here', 'today', ',', 'created', 'a', 'student', 'success', 'workshop', 'that', 'we', 'host', 'right', 'here', 'on', 'Open', 'ALG', 'as', 'well', '.', 'So', 'it', \"'s\", 'it', \"'s\", 'exciting']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chunks[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RplGPGmDFEph",
        "outputId": "6da9e5de-38e1-4816-eebf-d03774757628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['put', 'them', 'up', 'for', 'download', '.', 'If', 'you', \"'re\", 'creating', 'an', 'entirely', 'new', 'open', 'textbook', ',', 'then', 'we', \"'ll\", 'help', 'you', 'in', 'getting', 'this', 'into', 'manifold', 'in', 'a', 'really', 'cool', 'way', '.', 'We', 'even', 'have', 'some', 'training', 'resources', 'in', 'here', ',', 'including', 'a', 'champions', 'welcome', 'training', 'and', 'kickoff', 'training', ',', 'and', 'all', 'of', 'this', '.', 'These', 'are', 'entries', 'here', 'and', '.', 'You', 'know', ',', 'a', 'few', 'folks', 'from', 'Kennesaw', ',', 'including', 'a', 'few', 'that', 'are', 'here', 'today', ',', 'created', 'a', 'student', 'success', 'workshop', 'that', 'we', 'host', 'right', 'here', 'on', 'Open', 'ALG', 'as', 'well', '.', 'So', 'it', \"'s\", 'it', \"'s\", 'exciting', ',', 'it', \"'s\", 'a', 'new', 'home', 'for', 'these', 'resources', '.', 'It', 'does', \"n't\", 'link', 'up', 'to', 'our', 'library', 'discovery', 'system', 'the', 'way', 'that', 'Galileo', 'open', 'learning', 'materials', 'does', '.', 'And', 'therefore', 'we', 'have', 'both', 'and', 'we', 'create', 'entries', 'in', 'this', 'one', 'or', 'this', 'one', '.', 'Hopefully', 'that', 'will', 'be', 'fixed', 'in', 'the', 'future', '.', 'But', 'for', 'now', 'we', 'just', 'link', 'out', 'to', 'manifold', 'from', 'Galileo', 'open', 'learning', 'materials', 'to', 'make', 'our', 'stuff', 'maximally', 'discoverable', '.', 'Now', ',', 'along', 'with', 'all', 'of', 'this', ',', 'we', 'are', 'going', 'to', 'be', 'under', 'a', 'huge', 'change', 'very', 'soon', '.', 'We', 'have', 'been', 'working', 'with', 'the', 'web', 'person', 'for', 'Galileo', ',', 'Jason', 'Steele', ',', 'and', 'we', 'have', 'been', 'working', 'with', 'our', 'basically', 'our', 'our', 'marketing', 'coordinator', ',', 'Julie', 'Woodson', 'in', 'creating', 'a', 'new', 'way', 'to', 'tell', 'the', 'affordable', 'Learning', 'Georgia', 'story', 'and', 'get', 'people', 'to', 'where', 'they', 'need', 'to', 'go', '.', 'Uh', ',', 'in', 'in', 'a', 'new', 'website', '.', 'So', 'we', \"'ve\", 'been', 'working', 'on', 'this', 'for', 'quite', 'a', 'while', '.', 'We', \"'ve\", 'been', 'gathering', 'a', 'ton', 'of', 'feedback', 'for', 'years', 'and', 'we', \"'re\", 'finally', 'putting', 'all', 'of', 'that', 'into', 'practice', '.', 'So', 'this', 'will', 'be', 'the', 'new', 'ALG', 'website', '.', 'This', 'is', 'just', 'the', 'home', 'page', 'in', 'its', 'draft', 'form', '.', 'So', 'you', \"'re\", 'seeing', 'something', 'that', 'is', \"n't\", 'yet', 'out', 'there', '.', 'We', 'have', 'what', \"'s\", 'called', 'a', 'mega', 'menu', '.', 'So', 'now', 'if', 'you', 'have', 'a', 'navigation', 'element', ',', 'you', 'can', 'have', 'sub', 'navigation', 'in', 'here', '.', 'So', 'about', '.', 'About', 'us', 'and', 'about', 'OER', 'now', 'the', 'about', 'section', 'makes', 'a', 'way', 'more', 'sense', 'than', 'it', 'used', 'to', '.', 'Here', \"'s\", 'our', 'grants', ',', 'the', 'overview', 'of', 'grants', 'apply', 'for', 'our', 'grants', '.', 'And', 'here', \"'s\", 'the', 'Information', 'Center', 'page', 'that', 'we', 'keep', 'saying', '.', 'Please', 'bookmark', 'that', 'page', 'right', 'resources', '.', 'So', 'if', 'you', 'want', 'to', 'create', 'resources', ',', 'here', 'is', 'the', 'accessibility', 'guides', 'to', 'do', 'so', '.', 'Here', \"'s\", 'stuff', 'about', 'customizing', '.', 'Here', \"'s\", 'open', 'licensing', ',', 'finding', 'it', ',', 'learning', 'it', ',', 'and', 'then', 'we', 'have', 'a', 'new', 'way', 'to', 'announce', '.', 'News', 'and', 'I', 'can', 'not', 'wait', 'for', 'this', 'news', 'and', 'events', 'will', 'be', 'over', 'here', 'in', 'an', 'ALG', 'events', 'page', 'will', 'be', 'able', 'to', 'get', 'the', 'word', 'out', 'a', 'lot', 'more', 'efficiently', 'than', 'we', 'used', 'to', '.', 'All', 'of', 'this', 'is', 'still', 'not', 'out', 'there', 'in', 'published', 'yet', '.', 'This', 'is', 'just', 'a', 'quick', 'look', 'at', 'what', 'you', \"'re\", 'gon', 'na', 'see', ',', 'probably', 'by', 'the', 'end', 'of', 'January', 'into', 'February', ',', 'including', 'a', 'new', 'data', 'page', 'too', ',', 'which', 'is', 'still', 'all', 'of', 'this', 'is', 'still', 'being', 'worked', 'on', 'for', 'sure', ',', 'but', 'we', 'are', '.', 'In', 'the', 'the', 'home', 'stretch', 'of', 'releasing', 'a', 'new', 'web', 'page', '.', 'So', 'that', 'is', 'why', 'I', 'wanted', 'to', 'show', 'you', 'all', 'of', 'that', '.', 'So', 'we', \"'ve\", 'got', 'the', 'ALG', 'website', '.', 'It', 'directs', 'you', 'to', 'a', 'whole', 'bunch', 'of', 'cool', 'stuff', ',', 'but', 'if', 'you', 'want', 'to', 'get', 'to', 'the', 'most', 'important', 'things', ',', 'here', \"'s\", '.', 'Oh', ',', 'we', 'are', 'our', 'reports', 'and', 'everything', 'about', 'our', 'grants', 'and', 'the', 'big', 'buttons', '.', 'Galileo', 'Open', 'learning', 'materials', '.', 'Our', 'first', 'repository', 'connects', 'to', 'all', 'of', 'our', 'library', 'resources', 'to', 'so', 'we', 'are', 'able', 'to', 'share', 'all', 'of', 'the', 'old', 'OER', 'that', 'we', 'have', 'and', 'the', 'new', 'stuff', '.', 'Gets', 'put', 'into', 'manifold', ',', 'which', 'makes', 'it', 'way', 'more', 'interactive', '.', 'And', 'yeah', ',', 'that', \"'s\", 'just', 'a', 'quick', 'look', 'at', 'everything', 'that', 'we', 'have', '.', 'I', \"'m\", 'going', 'to', 'stop', 'sharing', 'this', '.', 'Here', 'we', 'go', 'and', 'I', \"'m\", 'going', 'to', 'go', 'back', 'into', 'sharing', 'the', 'PowerPoint', '.', 'I', 'wish', 'I', 'could', 'just', 'switch', 'between', 'them', ',', 'but', 'that', 'is', 'not', 'the', 'case', '.', 'There', 'we', 'are', '.', 'I', \"'m\", 'going', 'to', 'look', 'at', 'the', 'chat', 'for', 'a', 'second', 'there', '.', 'Ohh', 'someone', 'said', 'I', 'hear', 'a', 'cat', '.', 'Yeah', ',', 'so', 'I', 'I', 'did', 'a', 'mute', 'all', 'just', 'to', 'make', 'sure', 'that', '.', 'No', 'folks', 'were', 'OK', 'there', '.', 'Yeah', '.', 'So', 'does', 'anybody', 'have', 'any', 'questions', 'about', 'this', 'before', 'I', 'take', 'you', 'into', 'the', 'ALG', '.', 'Tracking', 'spreadsheet', 'to', 'let', 'you', 'know', 'how', 'that', 'looks', 'and', 'and', 'how', 'our', 'data', 'works', '.', 'OK', ',', 'the', 'link', 'to', 'the', 'uh', 'web', 'page', 'for', 'manifold', 'to', 'open', 'algisalg', '.', 'manifoldapp', '.', 'org', 'and', 'I', 'just', 'put', 'that', 'into', 'the', 'chat', '.', 'All', 'right', '.', 'The', 'next', 'thing', 'I', \"'m\", 'going', 'to', 'do', 'is', 'share', 'a', 'look', 'at', 'the', 'Excel', 'sheet', 'that', 'we', 'work', 'within', 'quite', 'a', 'bit', 'for', 'all', 'of', 'our', 'data', '.', 'So', 'that', 'you', 'know', 'what', 'happens', 'once', ',', 'especially', 'once', 'the', 'project', 'is', 'all', 'done', 'with', 'because', 'things', 'are', 'quite', 'interesting', 'from', 'that', 'point', 'onward', '.', 'OK', ',', 'so', 'this', 'is', 'a', 'very', 'very', 'big', 'sheet', 'of', 'grants', 'data', '.', 'Every', 'single', 'grant', 'that', 'we', 'have', ',', 'it', 'has', 'a', 'row', 'and', 'it', \"'s\", 'over', 'on', 'the', 'left', '.', 'So', 'there', \"'s\", 'the', 'the', 'grant', 'number', 'here', '.', 'We', \"'ve\", 'got', 'the', 'purchase', 'order', 'number', ',', 'which', 'is', 'helpful', 'for', 'the', 'business', 'office', '.', 'We', 'got', 'the', 'rounds', 'number', 'just', 'in', 'case', 'we', 'need', 'to', 'filter', 'by', 'what', 'happens', 'in', 'a', 'particular', 'round', ',', 'the', 'fiscal', 'year', 'just', 'in', 'case', 'that', \"'s\", 'different', 'the', 'type', '.', 'So', 'we', 'either', 'have', 'continuous', 'improvement', 'or', 'transformation', 'the', 'institution', '.', 'How', 'much', 'was', 'the', 'total', 'award', '?', 'This', 'is', 'important', 'for', 'the', 'last', 'entire', 'column', 'in', 'this', 'sheet', '.', 'The', 'final', 'semester', 'for', 'the', 'project', ',', 'which', 'means', 'that', 'this', 'is', 'the', 'first', 'time', 'that', 'implementation', 'is', 'guaranteed', '.', 'There', 'is', 'the', 'project', 'leads', 'name', 'and', 'e-mail', 'address', '.', 'We', 'will', 'contact', 'this', 'person', 'yearly', 'for', 'the', 'Sustainability', 'survey', ',', 'a', 'way', 'to', 'check', 'in', 'and', 'see', 'if', 'the', 'work', 'that', 'you', 'did', 'on', 'these', 'projects', 'is', 'still', 'ongoing', '.', 'If', 'those', 'savings', 'are', 'still', 'ongoing', '.', 'If', 'students', 'are', 'still', 'affected', 'that', 'way', ',', 'we', \"'ve\", 'got', 'the', 'course', 'names', ',', 'the', 'course', 'numbers', ',', 'and', 'the', 'USG', 'subject', 'area', 'that', 'this', 'is', 'a', 'part', 'of', '.', 'This', 'goes', 'by', 'the', 'academic', 'discipline', 'committees', 'that', 'are', 'here', '.', 'So', 'that', \"'s\", 'why', 'it', \"'s\", 'called', 'computing', 'disciplines', 'because', 'that', \"'s\", 'the', 'official', 'name', 'of', 'that', 'particular', 'academic', 'discipline', 'committee', '.', 'The', 'final', 'report', 'results', ',', 'there', 'are', 'three', 'big', 'questions', 'that', 'we', 'have', 'student', 'opinion', ',', 'student', 'performance', 'and', 'student', 'course', 'level', 'retention', '.', 'Whether', 'or', 'not', 'the', 'changes', 'in', 'them', 'or', 'positive', ',', 'neutral', 'or', 'negative', ',', 'then', 'we', 'have', 'the', 'annual', 'Savings', 'estimate', ',', 'annual', 'student', 'savings', 'per', 'student', ',', 'and', 'then', 'all', 'of', 'this', 'data', 'that', 'you', 'put', 'in', 'for', 'your', 'proposal', ',', 'it', \"'s\", 'the', 'students', 'per', 'summer', 'fall', 'and', 'spring', '.', 'And', 'if', 'the', 'first', 'implementation', 'semester', 'is', 'different', ',', 'it', 'will', 'be', 'marked', 'here', 'if', 'something', 'has', 'been', 'scaled', 'up', 'with', 'a', 'new', 'project', ',', 'we', 'ca', \"n't\", 'double', 'count', 'the', 'old', 'course', ',', 'so', 'we', 'have', 'to', 'put', 'that', '.', 'No', ',', 'this', 'project', 'was', 'not', 'scaled', 'up', '.', 'And', 'now', 'you', 'can', 'see', 'here', 'that', 'these', 'uh', 'did', 'not', 'get', 'started', 'in', 'spring', '2015', '.', 'It', 'was', 'a', 'while', '.', 'So', 'these', 'were', 'zeroed', 'out', ',', 'zeroed', 'out', ',', 'zeroed', 'out', 'for', 'a', 'little', 'bit', 'and', 'we', \"'re\", 'just', 'gon', 'na', 'keep', 'going', 'here', '.', 'Up', '.', 'Here', \"'s\", 'the', 'first', 'sustainability', 'check', '.', 'It', 'does', \"n't\", 'really', 'matter', 'that', 'these', 'are', 'continued', 'or', 'not', 'because', 'right', 'now', 'it', 'has', \"n't\", 'started', 'yet', '.', 'It', 'has', \"n't\", 'started', 'yet', '.', 'Fall', '2020', 'is', 'when', 'it', 'starts', '.', 'And', 'so', 'we', 'get', '2', 'faults', '1T20', 'and', 'bam', '.', 'All', 'right', '.', 'So', 'these', 'projects', 'that', 'started', 'over', 'here', 'in', 'fall', '.', '2020', '.', 'Suddenly', 'have', 'a', 'formula', 'in', 'the', 'column', 'for', 'fall', '2020', 'students', 'and', 'it', 'says', 'that', 'if', 'the', 'sustainability', 'check', 'is', 'continued', '.', 'Then', 'put', 'in', 'the', 'number', 'of', 'students', 'that', 'are', 'affected', 'per', 'fall', 'semester', '.', 'If', 'it', 'does', 'not', 'say', 'continued', ',', 'put', 'zero', '.', 'So', 'if', 'we', 'ca', \"n't\", 'find', 'you', 'and', 'we', 'do', \"n't\", 'know', 'the', 'status', 'of', 'your', 'sustainability', 'check', ',', 'we', 'put', 'unknown', 'and', 'unknown', 'is', '0', 'if', 'we', '.', 'Uh', ',', 'if', 'you', 'say', 'that', ',', 'yes', ',', 'it', \"'s\", 'been', 'discontinued', '.', 'We', 'put', 'discontinued', 'and', 'at', 'that', 'point', 'it', 'is', '0', 'and', 'then', 'everything', 'else', 'is', 'just', 'a', 'multiplier', 'from', 'there', '.', 'We', 'multiply', 'it', 'by', 'the', 'per', 'student', 'savings', 'as', 'marked', 'in', 'the', 'proposal', '.', 'And', 'then', 'as', 'updated', 'as', 'needed', 'in', 'the', 'sustainability', 'check', '.', 'And', 'going', 'onward', ',', 'things', 'start', 'to', 'happen', '.', 'We', 'did', 'not', 'know', 'the', 'status', 'of', '#', '478', 'and', 'therefore', 'this', 'got', 'zeroed', 'out', 'over', 'here', '.', 'This', 'one', 'was', 'discontinued', 'and', 'so', 'it', 'is', 'no', 'longer', 'running', '.', 'The', 'other', 'ones', 'are', 'continued', 'so', 'they', 'still', 'go', 'and', 'go', 'and', 'go', 'and', 'go', '.', 'We', 'have', 'hit', 'falls', '2022', '.', 'Some', 'of', 'the', 'old', 'projects', 'or', 'the', 'mini', 'grants', 'where', 'they', 'do', 'not', 'have', 'savings', 'attached', 'to', 'them', 'because', 'they', 'are', 'not', '.', 'Uh', '.', 'Geared', 'towards', 'uh', '?', 'Increase', 'student', 'savings', '.', 'They', \"'re\", 'in', '.', 'They', \"'re\", 'geared', 'towards', 'sustainability', 'and', 'continuous', 'improvement', '.', 'So', 'those', 'sometimes', 'the', 'formulas', 'like', ',', 'hey', ',', 'we', 'do', \"n't\", 'have', 'a', 'value', 'here', '.', 'Well', ',', 'yeah', ',', 'of', 'course', 'you', 'do', \"n't\", '.', 'These', 'were', \"n't\", 'ones', 'that', 'we', 'were', 'targeting', 'here', ',', 'though', '.', 'Here', \"'s\", 'the', 'grand', 'total', 'of', 'students', 'affected', 'during', 'the', 'project', '.', 'Here', \"'s\", 'the', 'grand', 'total', 'of', 'savings', 'that', 'have', 'happened', 'ever', 'since', 'the', 'project', 'got', 'implemented', '.', 'And', 'then', 'using', 'the', 'award', 'amount', 'from', 'the', 'beginning', ',', 'we', 'do', 'the', 'savings', 'per', '$', '1', '.', '00', 'awarded', '.', 'And', 'over', 'the', 'total', 'award', ',', 'so', 'you', 'can', 'see', 'here', 'that', 'the', 'the', 'return', 'on', 'investment', 'when', 'it', 'comes', 'to', 'student', 'savings', 'can', 'be', 'pretty', 'high', '.', 'It', \"'s\", 'pretty', 'awesome', '.', 'So', 'that', \"'s\", 'where', 'you', \"'re\", 'going', 'to', 'see', 'a', 'lot', 'of', 'this', 'data', 'that', 'happens', 'later', 'on', '.', 'You', \"'re\", 'in', 'the', 'very', 'beginning', 'stages', 'of', 'all', 'that', '.', 'So', 'some', 'of', 'this', 'you', \"'re\", 'probably', 'looking', 'at', 'what', 'the', 'heck', ',', 'but', 'This', 'is', 'why', 'we', 'will', 'keep', 'in', 'contact', 'with', 'you', 'after', 'the', 'grant', 'process', 'is', 'all', 'done', '.', 'It', \"'s\", 'why', 'our', 'sustainability', 'surveys', 'are', 'so', 'important', ',', 'and', 'it', \"'s\", 'really', 'important', 'in', 'keeping', 'our', 'data', 'accurate', 'and', 'making', 'sure', 'that', 'things', 'are', 'still', 'ongoing', '.', 'So', 'that', 'is', 'the', 'other', 'part', 'of', 'the', 'Grand', 'Tour', 'of', 'ALG', '.', 'It', \"'s\", 'kind', 'of', 'a', 'a', 'look', 'behind', 'the', 'scenes', 'over', 'in', ',', 'in', 'the', 'backstage', 'room', 'to', 'see', 'what', \"'s\", 'going', 'on', 'over', 'there', '.', 'So', 'now', 'I', \"'m\", 'gon', 'na', 'open', 'up', 'this', 'presentation', 'again', '.', 'Ant', 'now', '.', 'OK', ',', 'we', 'do', \"n't\", 'need', '.', 'Yeah', ',', 'it', \"'s\", '122', '.', 'Excellent', '.', 'Great', '.', 'Alright', '.', 'So', 'now', 'we', 'are', 'going', 'to', 'do', 'introductions', '.', 'Let', 'me', 'start', 'up', 'my', 'camera', 'here', '.', 'Everyone', '.', 'Ohh', 'Yep', ',', 'I', 'am', 'in', 'my', 'office', 'in', 'Athens', '.', 'It', \"'s\", 'good', 'to', 'see', 'you', 'all', '.', 'You', \"'ll\", 'see', 'some', 'open', 'Stax', 'texts', 'right', 'here', '.', 'Open', 'stacks', 'has', 'print', 'resources', 'and', 'they', 'send', 'some', 'of', 'those', 'out', 'along', 'time', 'ago', 'to', 'show', 'that', '.', 'Yes', ',', 'these', 'are', 'indeed', 'giant', 'textbooks', 'that', 'can', 'be', 'printed', 'out', '.', 'If', 'you', 'would', 'like', '.', 'Uh', ',', 'yeah', ',', 'it', \"'s\", 'it', \"'s\", 'been', 'great', 'to', 'be', 'running']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if chunks[0][-100:] == chunks[1][:100]:\n",
        "    print('Overlap is Good')\n",
        "else:\n",
        "    print('Overlap is Not Good')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRszfXxmKWS0",
        "outputId": "3b2bfc9e-2ee9-4db6-c9cc-f4b80254cf77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overlap is Good\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.7. Set OpenAI API Key"
      ],
      "metadata": {
        "id": "I7ZEq816LCWr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please note that OpenAI's API service is not free, unlike ChatGPT demo. You will need to sign up for a service with them to get an API key, which requires payment information."
      ],
      "metadata": {
        "id": "lyDKuS7CLHJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set an environment variable called “OPEN_API_KEY” and assign a secret API key from OpenAI (https://beta.openai.com/account/api-keys)."
      ],
      "metadata": {
        "id": "1gnYy6NrLJf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = 'paste your openai api key here'"
      ],
      "metadata": {
        "id": "GL4KCDfsK3mD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "NALIE4VOLfEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.8. Convert the NLTK Tokenized Text to Non-Tokenized Text"
      ],
      "metadata": {
        "id": "sHaUZ44wnama"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will need to convert the NLTK tokenized text to non-tokenized text since OpenAI GPT-3 API does not know how to handle tokenized text very well."
      ],
      "metadata": {
        "id": "SosiCP6SoGzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_prompt_text(tokenized_text):\n",
        "    prompt_text = \" \".join(tokenized_text)\n",
        "    prompt_text = prompt_text.replace(\" 's\", \"'s\")\n",
        "    return prompt_text"
      ],
      "metadata": {
        "id": "RzV52DsaQ3g9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.9. Summarize the Meeting Transcript"
      ],
      "metadata": {
        "id": "_LgrIt-an-7T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2.9.1. Summarize the Meeting Transcript one chunk at a time."
      ],
      "metadata": {
        "id": "xBSXqVbJom1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"/content/drive/MyDrive/Colab Notebooks/minutes/data/Round_22_Online_Kickoff_Meeting.txt\"\n",
        "#response = []\n",
        "prompt_response = []\n",
        "\n",
        "chunks = break_up_file_to_chunks(filename)\n",
        "for i, chunk in enumerate(chunks):\n",
        "    prompt_request = \"Summarize this meeting transcript: \" + convert_to_prompt_text(chunks[i])\n",
        "\n",
        "    response = openai.Completion.create(\n",
        "            model=\"text-davinci-003\",\n",
        "            prompt=prompt_request,\n",
        "            temperature=.5,\n",
        "            max_tokens=500,\n",
        "            top_p=1,\n",
        "            frequency_penalty=0,\n",
        "            presence_penalty=0\n",
        "    )\n",
        "    \n",
        "    prompt_response.append(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "id": "oFfyvbntLxuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsbvQ19pSKw5",
        "outputId": "613c9726-2e68-4993-ae04-d74f09f46811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' to see all the different ways that you can use this repository .\\n\\nThis meeting was a kickoff meeting for the 22 grants that were awarded. It went over the Affordable Learning Georgia (ALG) website, which is the hub for everything that ALG offers. It also discussed the grant procedure and the ALG grants equivalence of the syllabus. There was also a discussion on the two big homes for OER created through the grants, Galileo open learning materials and Manifold. Finally, there was a discussion on the training resources available on Open ALG.',\n",
              " ' around and talking about ALG and all of the cool stuff that we have going on .\\n\\nThis meeting discussed the resources available to help create open textbooks, including training resources and entries on Open ALG. They discussed the new ALG website that they have been working on with feedback from users and the new mega menu. They also discussed the resources available on manifold, which is connected to the library discovery system, and the Galileo Open Learning Materials repository. They also discussed the ALG tracking spreadsheet, where they track data such as the grant number, the type of grant, the course name, and the USG subject area. Finally, they discussed the sustainability survey, which is used to check in and see if the work done on the project is still ongoing.',\n",
              " ' videos , a lot of them , and we are also developing a lot of interactive simulations . We are also developing a lot of laboratory activities and we are developing a new grading system . So we are very excited about it . And we are looking forward to getting the book out in the spring semester . Excellent . Thank you so much .\\n\\nThis meeting was a gathering of representatives from various universities to discuss their ALG grants. Each team is transforming a textbook into an open stacks book and developing instructional videos, interactive simulations, laboratory activities, and new grading systems. The teams are from the University of West Georgia, Clayton State University, University of North Georgia, Georgia Gwinnett College, and Georgia Gwinnett College. The projects range from transforming a Spanish textbook, a microbiology course, an introductory physics course for biology students, a survey of chemistry course for allied health majors, and an introduction to anthropology textbook. The teams are hoping to have the books ready for the spring semester.',\n",
              " \" is Antara Dutta and I 'm a faculty member in the Department of Physics at Georgia State University . I 'm here with my team , which is comprised of four faculty members , one staff member and one student . Our project is focused on transforming a traditional calculus based introductory physics course into a more inquiry based course . We are working on creating and revising lab activities to include more inquiry based activities and simulations , and we are also working on developing instructional videos and lecture notes . We are also working on creating a course website to host the various materials and resources . Our timeline is similar to everyone else's and we are hoping to have the course ready by Fall 2021 . That's it . Thank you .\\n\\nThis meeting was a gathering of teams from Georgia Gwinnett College, College of Coastal Georgia, Kennesaw State University, Georgia Southern University, Georgia Tech, and Augusta University, who are all recipients of the ALG grant. Each team discussed their project, which involves transforming, revising, and developing instructional materials for various courses, such as mechanics, biology, autonomous vehicle sensors, PLC programmable logic controllers, English 1101 and 1102, and introductory physics. The materials will include videos, annotation, lab activities, lecture notes, quizzes, multimedia links, and more. The teams are working to have the materials ready by Fall 2021.\",\n",
              " \" now , we 're going to move on to the next group .\\n\\nThis meeting was a gathering of representatives from different institutions discussing their Affordable Learning Georgia (ALG) grants. These grants are focused on creating digital textbooks, interactive simulations, and other learning materials to replace traditional textbooks, with a focus on affordability and diversity and inclusion. The representatives discussed their projects, which included creating a general chemistry textbook, an anatomy and physiology lab manual, an English composition module, a physical science textbook, and a calculus textbook. They also discussed hiring student assistants for usability testing and creating instructor solutions.\",\n",
              " \" purchased , how they're stored , and how they're distributed . We want to make sure that all of that is in line with your institution's common practices . So this is a summary of a meeting transcript discussing the grant procedures for continuous improvement grants. It covers topics such as funding, service level agreements, invoices and reports, and other topics related to the grant process. It also explains how the USG and the institution are considered part of the same organization, and how funding is released in two parts.\",\n",
              " \" a few things with family and then I 'll be back . So I 'm going to be out of commission for a while , so please do reach out to me if you have any questions .\\n\\nThis meeting discussed the Service Level Agreement (SLA) between the USG and the institution. It went over the different parts of the SLA, such as the statement of work, the budget, the start and end dates, how project funding works, what to do if something goes wrong, and the legal compliance. It also mentioned that the SLA will be sent to the business or grants office and that if something looks off, the project lead should reach out. It concluded with the speaker mentioning that they will be out of commission for a while.\",\n",
              " \" the final report . It's not actually required . But if you do want to send a photo , that's really cool . We love to see those and then the survey link . And then we have the option for you to upload any other materials . This could be PowerPoint slides , videos , anything like that . That's a great way to just get it all in one place .\\n\\nThis meeting discussed the process of sending out dates and budgets to business or grants office contacts, and the steps that need to be taken in order to pay invoices. It also discussed the timeline for submitting semester status reports and final reports, as well as the information that should be included in the reports. Lastly, it discussed the requirement to use the three digit number on the SLA and the importance of submitting the final report in a Word document.\",\n",
              " '\\n\\nThis meeting discussed procedures for submitting documents and materials, reporting deadlines, and other important information related to the ALG grantees. It also went over how to submit photos, syllabi, and other documents. It was noted that the SLA would be sent out on Monday and that if any questions arise between the 16th and the 2nd, they should be sent to the administrator. The meeting concluded by wishing everyone a happy holiday.']"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2.9.2. Consolidate the Meeting Transcript Summaries."
      ],
      "metadata": {
        "id": "rL1451Igozer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_request = \"Consoloidate these meeting summaries: \" + str(prompt_response)\n",
        "\n",
        "response = openai.Completion.create(\n",
        "        model=\"text-davinci-003\",\n",
        "        prompt=prompt_request,\n",
        "        temperature=.5,\n",
        "        max_tokens=1000,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )"
      ],
      "metadata": {
        "id": "5eh0cVS0PW5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meeting_summary = response[\"choices\"][0][\"text\"]\n",
        "print(meeting_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "yu_cQjLDTAB4",
        "outputId": "61eafb09-5f06-49a9-8785-0aead56065f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "This meeting was a gathering of representatives from various universities to discuss their ALG grants. Each team is transforming a textbook into an open stacks book and developing instructional videos, interactive simulations, laboratory activities, and new grading systems. The teams are from the University of West Georgia, Clayton State University, University of North Georgia, Georgia Gwinnett College, and Georgia Gwinnett College. The projects range from transforming a Spanish textbook, a microbiology course, an introductory physics course for biology students, a survey of chemistry course for allied health majors, and an introduction to anthropology textbook. They also discussed the new ALG website that they have been working on with feedback from users and the new mega menu, the resources available on manifold, which is connected to the library discovery system, and the Galileo Open Learning Materials repository, the ALG tracking spreadsheet, where they track data such as the grant number, the type of grant, the course name, and the USG subject area, the sustainability survey, which is used to check in and see if the work done on the project is still ongoing, and the resources available to help create open textbooks, including training resources and entries on Open ALG. This meeting also discussed procedures for submitting documents and materials, reporting deadlines, and other important information related to the ALG grantees, such as how to submit photos, syllabi, and other documents, the Service Level Agreement (SLA) between the USG and the institution, and the process of sending out dates and budgets to business or grants office contacts and the steps that need to be taken in order to pay invoices. The teams are hoping to have the books ready for the spring semester and the meeting concluded by wishing everyone a happy holiday.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.10. Get Action Items from Meeting Transcript"
      ],
      "metadata": {
        "id": "MRwpgJ1gpPhL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2.10.1. Get Action Items from the Meeting Transcript one chunk at a time."
      ],
      "metadata": {
        "id": "nhZfit-nplpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"/content/drive/MyDrive/Colab Notebooks/minutes/data/Round_22_Online_Kickoff_Meeting.txt\"\n",
        "\n",
        "action_response = []\n",
        "\n",
        "chunks = break_up_file_to_chunks(filename)\n",
        "for i, chunk in enumerate(chunks):\n",
        "    prompt_request = \"Provide a list of action items with a due date from the provided meeting transcript text: \" + convert_to_prompt_text(chunks[i])\n",
        "\n",
        "    response = openai.Completion.create(\n",
        "            model=\"text-davinci-003\",\n",
        "            prompt=prompt_request,\n",
        "            temperature=.5,\n",
        "            max_tokens=500,\n",
        "            top_p=1,\n",
        "            frequency_penalty=0,\n",
        "            presence_penalty=0\n",
        "    )\n",
        "    \n",
        "    action_response.append(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "JvHJV8KeUzeS",
        "outputId": "b6a3ddb8-7834-4890-e3f3-8fb333de4c29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(action_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZNzPeL8SVJSG",
        "outputId": "29b5d65d-b39f-4b64-e45a-c35d5a5c13e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\" to see all of this stuff here . And then if you want to see what other folks are doing , you can go over to the project page . This is where all the grants that we 've awarded since 2016 , all the way up to the current ones , all of them are listed here . You can see the status of them . You can see the titles and you can even see if they have a project page or not . So if you 're looking for something specific , you can go right here and search for it . And if you 're looking for something in the same discipline , you can go to the same discipline and see what other projects are out there . So it's really exciting to see what folks are doing . So that's a quick overview of the ALG website . I 'm going to go back to the slides here and I 'm going to go to the next section .\\n\\nAction Item 1: Introduce participants and have everyone share a greeting - Due Date: Immediately \\nAction Item 2: Go through ALG website - Due Date: Immediately \\nAction Item 3: Go over grant procedures - Due Date: Immediately \\nAction Item 4: Go over OER repositories - Due Date: Immediately \\nAction Item 5: Go over grant deadlines and reporting guidelines - Due Date: Immediately \\nAction Item 6: Go over Manifold repository - Due Date: Immediately \\nAction Item 7: Go over project page - Due Date: Immediately \\nAction Item 8: Submit report by December 19th - Due Date: December 19th\", \" around the state . I 've been to a few institutions . I 've been to Kennesaw . I 've been to Valdosta . I 've been to Perimeter . I 've been to Georgia Tech . It's been great to get to meet some of the folks who are doing this work . And I look forward to getting to meet more people as we get going .\\n\\nAction Items:\\n\\n1. Put resources up for download - Due Date: ASAP\\n2. Create entries in Open ALG and Manifold - Due Date: ASAP\\n3. Create a new ALG website - Due Date: End of January/Beginning of February\\n4. Create a mega menu - Due Date: End of January/Beginning of February\\n5. Create a new Data Page - Due Date: End of January/Beginning of February\\n6. Create a new ALG Events Page - Due Date: End of January/Beginning of February\\n7. Create an Accessibility Guide - Due Date: End of January/Beginning of February\\n8. Contact project leads yearly for sustainability survey - Due Date: Ongoing\", ' video library that will be integrated into the course . We are also developing a problem solving library and a quiz library , and we are also developing a virtual lab experience . We are also developing a virtual lab experience . We are also developing a problem solving library and a quiz library , and we are also developing a virtual lab experience .\\n\\nAction Items:\\n\\n1. Begin hiring process for Program Manager (January 2021)\\n2. Develop demonstration videos for laboratory techniques for UWG project (Due Date: TBD)\\n3. Develop group work activities for UWG project (Due Date: TBD)\\n4. Redevelop laboratory component for UWG project (Due Date: TBD)\\n5. Generate a OER textbook for Clayton State project (Due Date: TBD)\\n6. Develop specification based grading system for UNG project (Due Date: TBD)\\n7. Transform introduction to anthropology textbook for GGC project (Due Date: TBD)\\n8. Hire students to write vignettes and case studies for GGC project (Due Date: TBD)\\n9. Transform algebra based physics one course for GGC project (Due Date: TBD)\\n10. Develop instructional video library for GGC project (Due Date: TBD)\\n11. Develop problem solving library for GGC project (Due Date: TBD)\\n12. Develop quiz library for GGC project (Due Date: TBD)\\n13. Develop virtual lab experience for GGC project (Due Date: TBD)', \" is Antara Dutta and I'm working with Dr. Marcella and Dr. Hwang on this project . We're transforming two of our courses , one is an introduction to computer science and the other one is an introduction to software engineering . So we're working on revising the materials for the syllabus . We are also creating a lab manual and we are also creating some videos that are going to be used in the course . We're also looking at different ways to engage the students and to get them more interested in the topics that we are teaching . So we're really excited about this project and looking forward to the outcome . Thank you . All right . Action Items: \\n1. Email Amy Battles about hosting resources - Due Date: ASAP \\n2. Create comprehensive textbook free textbook package (including materials that easily pass digital accessibility, Word documents, PPTX, quizzes, multimedia links) - Due Date: Fall \\n3. Develop new custom lab manuals for introductory biology sequence - Due Date: Fall \\n4. Create instructional videos for mechanics course - Due Date: Fall \\n5. Create instructional videos for labs - Due Date: Fall \\n6. Rewrite labs - Due Date: Fall \\n7. Create new labs - Due Date: Fall \\n8. Revise and repurpose labs to better align with learning objectives - Due Date: Fall \\n9. Replace conventional cookbook labs with more inquiry based activities - Due Date: Fall \\n10. Transform textbooks and lab materials for Autonomous Vehicle Sensors and PLC Programmable Logic Controllers courses - Due Date: Fall \\n11. Move from custom published text to Open Access - Due Date: Fall \\n12. Create a math primer, series of videos and online resources to improve understanding and retention in engineering courses - Due Date: Fall \\n13. Create videos on topics to make material broad levels - Due Date: Fall \\n14. Revise materials for Introduction to Computer Science and Introduction to Software Engineering courses - Due Date: Fall \\n15. Create lab manual for Introduction to Computer Science and Introduction to Software Engineering courses - Due Date: Fall \\n16. Create videos for Introduction to Computer Science and Introduction to Software Engineering courses - Due Date: Fall \\n17. Look at different ways to engage students - Due Date: Fall\", ' now .\\n\\nAction Items:\\n\\n1. Antara Dutta and her team: Create a digital textbook for Chemistry 1212 by Fall 2022 - Due Date: Fall 2022\\n\\n2. Karen Wiles and her team: Create an Atlas for Histology and a Workbook for Anatomy and Physiology - Due Date: TBD\\n\\n3. Li Messi and her team: Compile resources and create a textbook for Physical Science One - Due Date: TBD\\n\\n4. Amelia Lewis and her team: Create affordable learning modules to replace textbooks with a focus on diversity and inclusion - Due Date: Fall 2021\\n\\n5. Ben Kamau and his team: Reduce cost for students, improve teaching and learning in calculus, create multiple representations of calculus concepts, and review existing material - Due Date: TBD\\n\\n6. Sandip Dust and his team: Write a new textbook with open source materials and create instructor solutions - Due Date: TBD', \" distributed . So if you 're creating physical materials , that's totally fine . We 'll cover that . But then you 've got to figure out how you 're going to get those physical materials to students . And that's something that you 'll have to work out with your institution . So that's kind of the way that the funding works .\\n\\nAction Items:\\n\\n1. Provide introductions in the chat about Continuous Improvement Grant Projects by 2:17 PM - Due Date: 2:17 PM\\n\\n2. Jump 15 minutes ahead in the recording by 2:17 PM - Due Date: 2:17 PM\\n\\n3. Start discussing grant procedures by 2:17 PM - Due Date: 2:17 PM\\n\\n4. Reach out to business and grants office to understand institutional policies by 2:17 PM - Due Date: 2:17 PM\\n\\n5. Understand how students and external consultants are compensated by 2:17 PM - Due Date: 2:17 PM\\n\\n6. Plan how physical and digital materials will be distributed by 2:17 PM - Due Date: 2:17 PM\", \" some family stuff . So if you have any questions , please reach out to the team . We 'll be here to help .\\n\\nAction Items: \\n1. Draft SLAs by Monday - Due Date: Monday\\n2. Send SLAs to project leads - Due Date: Monday\\n3. Reach out to Business or Grants Office if something looks weird - Due Date: Monday\\n4. Check dates and budgets - Due Date: Monday\\n5. Reach out to team if any questions - Due Date: Friday\", \" the final report . We do n't need it . It's just . It's just kind of a fun thing . It's not mandatory . And then of course , the final report form . So that's the that's the final report .\\n\\nAction Items:\\n\\n1. Reach out to business or grants office if anything looks weird by December 15th\\n2. Check in every semester to let us know how it's going by December 15th\\n3. Make sure invoice comes from institution as an organization by December 15th\\n4. Submit semester status report in Google form for Spring 2023 by December 15th\\n5. Submit final report in Word form by Fall 2023\", '\\n\\nAction Items: \\n1. Have all data ready for online form (due 12/19)\\n2. Have syllabi ready (due 12/19)\\n3. Have optional photo of team ready (due 12/19)\\n4. Have second invoice ready (due 12/19)\\n5. Have Word document version ready (due 12/19)\\n6. Have materials in cloud storage, Google Drive, Dropbox, or Microsoft OneDrive (due 12/19)\\n7. Have team photo ready (due 12/19)\\n8. Send SLA to Dina Anderson (due 12/14)\\n9. Send timeline to Jeff Gallant (due 12/19)\\n10. Save Grants Information Center link (due 12/19)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2.10.2. Consolidate the Meeting Transcript Action Items."
      ],
      "metadata": {
        "id": "_Od7s1fwpdy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_request = \"Consoloidate these meeting action items: \" + str(action_response)\n",
        "\n",
        "response = openai.Completion.create(\n",
        "        model=\"text-davinci-003\",\n",
        "        prompt=prompt_request,\n",
        "        temperature=.5,\n",
        "        max_tokens=500,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "MISAIRbJWamn",
        "outputId": "74c5df2c-71a8-48b3-c972-3f4bc489c80c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "meeting_action_items = response[\"choices\"][0][\"text\"]\n",
        "print(meeting_action_items)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "5b3aowAFWjdY",
        "outputId": "03e7f6c1-5a72-415f-d102-01a6b5e1a0aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Action Items: \n",
            "1. Introduce participants and have everyone share a greeting - Due Date: Immediately\n",
            "2. Go through ALG website - Due Date: Immediately\n",
            "3. Go over grant procedures - Due Date: Immediately\n",
            "4. Go over OER repositories - Due Date: Immediately\n",
            "5. Go over grant deadlines and reporting guidelines - Due Date: Immediately\n",
            "6. Go over Manifold repository - Due Date: Immediately\n",
            "7. Go over project page - Due Date: Immediately\n",
            "8. Submit report by December 19th - Due Date: December 19th\n",
            "9. Put resources up for download - Due Date: ASAP\n",
            "10. Create entries in Open ALG and Manifold - Due Date: ASAP\n",
            "11. Create a new ALG website - Due Date: End of January/Beginning of February\n",
            "12. Create a mega menu - Due Date: End of January/Beginning of February\n",
            "13. Create a new Data Page - Due Date: End of January/Beginning of February\n",
            "14. Create a new ALG Events Page - Due Date: End of January/Beginning of February\n",
            "15. Create an Accessibility Guide - Due Date: End of January/Beginning of February\n",
            "16. Contact project leads yearly for sustainability survey - Due Date: Ongoing\n",
            "17. Begin hiring process for Program Manager (January 2021)\n",
            "18. Develop demonstration videos for laboratory techniques for UWG project (Due Date: TBD)\n",
            "19. Develop group work activities for UWG project (Due Date: TBD)\n",
            "20. Redevelop laboratory component for UWG project (Due Date: TBD)\n",
            "21. Generate a OER textbook for Clayton State project (Due Date: TBD)\n",
            "22. Develop specification based grading system for UNG project (Due Date: TBD)\n",
            "23. Transform introduction to anthropology textbook for GGC project (Due Date: TBD)\n",
            "24. Hire students to write vignettes and case studies for GGC project (Due Date: TBD)\n",
            "25. Transform algebra based physics one course for GGC project (Due Date: TBD)\n",
            "26. Develop instructional video library for GGC project (Due Date: TBD)\n",
            "27. Develop problem solving library for GGC project (Due Date: TBD)\n",
            "28. Develop quiz library for GGC project (Due Date: TBD)\n",
            "29. Develop virtual lab experience for GGC project (Due Date: TBD)\n",
            "30. Antara D\n"
          ]
        }
      ]
    }
  ]
}