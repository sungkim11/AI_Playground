{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxuVRvyXC9kYZmHDlC/COX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sungkim11/ai-playground/blob/main/Create_Meeting_Minutes_Using_AI_Workbook_Tranformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create a Meeting Minute using OpenAI's GPT-3 from both Microsoft Team's Meeting Transcript or Zoom's Meeting Transcript (Transformers)"
      ],
      "metadata": {
        "id": "vC0t_IHQgV6-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is my endeavor to replicate upcoming Microsoft Team Premium feature to create meeting notes using AI."
      ],
      "metadata": {
        "id": "N7R-tsFJgr7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Prerequisites"
      ],
      "metadata": {
        "id": "4b_S-B5jg7f2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following are prerequisites for this tutorial:\n",
        "\n",
        "- Python Package: openai\n",
        "- Python Package: torch and transformers"
      ],
      "metadata": {
        "id": "DfTwEED_g_kb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.1. Python Packages"
      ],
      "metadata": {
        "id": "hEIroo2BhEzH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####1.1.1. Install Python Packages"
      ],
      "metadata": {
        "id": "z8G98yU0z8y_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uNn49xIzMq7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e5a72f89-95bb-4f61-dfa1-e3a91bc8a8e9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile requirements.txt\n",
        "openai\n",
        "torch==1.13.1+cu116\n",
        "transformers==4.26.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "fdJwUNoszSIp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "outputId": "7c6d83da-938e-4432-88c2-1b84051ffb24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (0.26.5)\n",
            "Requirement already satisfied: torch==1.13.1+cu116 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (1.13.1+cu116)\n",
            "Requirement already satisfied: transformers==4.26.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 3)) (4.26.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1+cu116->-r requirements.txt (line 2)) (4.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.1->-r requirements.txt (line 3)) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.1->-r requirements.txt (line 3)) (0.13.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.1->-r requirements.txt (line 3)) (2.25.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.1->-r requirements.txt (line 3)) (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.1->-r requirements.txt (line 3)) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.1->-r requirements.txt (line 3)) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.1->-r requirements.txt (line 3)) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.1->-r requirements.txt (line 3)) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.1->-r requirements.txt (line 3)) (23.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from openai->-r requirements.txt (line 1)) (3.8.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.26.1->-r requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.26.1->-r requirements.txt (line 3)) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.26.1->-r requirements.txt (line 3)) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.26.1->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai->-r requirements.txt (line 1)) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai->-r requirements.txt (line 1)) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai->-r requirements.txt (line 1)) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai->-r requirements.txt (line 1)) (2.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai->-r requirements.txt (line 1)) (22.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai->-r requirements.txt (line 1)) (6.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Code"
      ],
      "metadata": {
        "id": "dzLhnP--hOxp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colab code to prettify text output."
      ],
      "metadata": {
        "id": "lGFFGcY1tasJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "Ow3tBDBfseRE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f94880a8-846c-4500-d576-e1756118bd0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.1. Import Python Packages"
      ],
      "metadata": {
        "id": "WmRPmprK0GM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import platform\n",
        "import os\n",
        "\n",
        "import openai\n",
        "\n",
        "import re\n",
        "from os.path import splitext, exists\n",
        "\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "print('Python: ', platform.python_version())\n",
        "print('re: ', re.__version__)\n",
        "print('torch: ', torch.__version__)\n",
        "print('transformers: ', transformers.__version__)"
      ],
      "metadata": {
        "id": "0Zs3zeEy0HXX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "0fe7d7c4-f403-4580-a4f3-71fb6a489cf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python:  3.8.10\n",
            "re:  2.2.1\n",
            "torch:  1.13.1+cu116\n",
            "transformers:  4.26.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.2. Mount Storage - Google Drive"
      ],
      "metadata": {
        "id": "_5EJ0NJHzmxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Tx1d61zFzkMT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a8116f8c-c0b4-450e-8285-3ead7d3239a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.3. Clean Meeting Transcript from either Microsoft Team or Zoom, encoded as WEBVTT file."
      ],
      "metadata": {
        "id": "qj6-FtO2zsb8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The meeting transcript is encoded as follows:\n",
        "\n",
        "    WEBVTT\n",
        "    \n",
        "    03951482-18bc-403b-9a4f-9d2699587f03/65-1\n",
        "    00:00:08.885 --> 00:00:13.589\n",
        "    transcription making sure that\n",
        "    the transcription does work. Yep"
      ],
      "metadata": {
        "id": "jvuyPQvdiTq1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is not usually problem with ChatGPT, but OpenAI GPT-3 API charges by a token and we want to minimize the number of tokens sending to it. We will need to remove all lines that is not a transcript."
      ],
      "metadata": {
        "id": "dW6bAm4WjRTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These two functions clean up .vtt file and then produce a clean text file with the same filename with an extension of .txt."
      ],
      "metadata": {
        "id": "5I6qHWX9kJb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_webvtt(filepath: str) -> str:\n",
        "    \"\"\"Clean up the content of a subtitle file (vtt) to a string\n",
        "\n",
        "    Args:\n",
        "        filepath (str): path to vtt file\n",
        "\n",
        "    Returns:\n",
        "        str: clean content\n",
        "    \"\"\"\n",
        "    # read file content\n",
        "    with open(filepath, \"r\", encoding=\"utf-8\") as fp:\n",
        "        content = fp.read()\n",
        "\n",
        "    # remove header & empty lines\n",
        "    lines = [line.strip() for line in content.split(\"\\n\") if line.strip()]\n",
        "    lines = lines[1:] if lines[0].upper() == \"WEBVTT\" else lines\n",
        "\n",
        "    # remove indexes\n",
        "    lines = [lines[i] for i in range(len(lines)) if not lines[i].isdigit()]\n",
        "\n",
        "    # remove tcode\n",
        "    #pattern = re.compile(r'^[0-9:.]{12} --> [0-9:.]{12}')\n",
        "    pattern = r'[a-f\\d]{8}-[a-f\\d]{4}-[a-f\\d]{4}-[a-f\\d]{4}-[a-f\\d]{12}\\/\\d+-\\d'\n",
        "    lines = [lines[i] for i in range(len(lines))\n",
        "             if not re.match(pattern, lines[i])]\n",
        "\n",
        "    # remove timestamps\n",
        "    pattern = r\"^\\d{2}:\\d{2}:\\d{2}.\\d{3}.*\\d{2}:\\d{2}:\\d{2}.\\d{3}$\"\n",
        "    lines = [lines[i] for i in range(len(lines))\n",
        "             if not re.match(pattern, lines[i])]\n",
        "\n",
        "    content = \" \".join(lines)\n",
        "\n",
        "    # remove duplicate spaces\n",
        "    pattern = r\"\\s+\"\n",
        "    content = re.sub(pattern, r\" \", content)\n",
        "\n",
        "    # add space after punctuation marks if it doesn't exist\n",
        "    pattern = r\"([\\.!?])(\\w)\"\n",
        "    content = re.sub(pattern, r\"\\1 \\2\", content)\n",
        "\n",
        "    return content\n",
        "\n",
        "\n",
        "def vtt_to_clean_file(file_in: str, file_out=None, **kwargs) -> str:\n",
        "    \"\"\"Save clean content of a subtitle file to text file\n",
        "\n",
        "    Args:\n",
        "        file_in (str): path to vtt file\n",
        "        file_out (None, optional): path to text file\n",
        "        **kwargs (optional): arguments for other parameters\n",
        "            - no_message (bool): do not show message of result.\n",
        "                                 Default is False\n",
        "\n",
        "    Returns:\n",
        "        str: path to text file\n",
        "    \"\"\"\n",
        "    # set default values\n",
        "    no_message = kwargs.get(\"no_message\", False)\n",
        "    if not file_out:\n",
        "        filename = splitext(file_in)[0]\n",
        "        file_out = \"%s.txt\" % filename\n",
        "        i = 0\n",
        "        while exists(file_out):\n",
        "            i += 1\n",
        "            file_out = \"%s_%s.txt\" % (filename, i)\n",
        "\n",
        "    content = clean_webvtt(file_in)\n",
        "    with open(file_out, \"w+\", encoding=\"utf-8\") as fp:\n",
        "        fp.write(content)\n",
        "    if not no_message:\n",
        "        print(\"clean content is written to file: %s\" % file_out)\n",
        "\n",
        "    return file_out"
      ],
      "metadata": {
        "id": "d1T3XitJ1Z58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6c399063-e9f6-4138-968f-a6fcbcb82319"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"/content/drive/MyDrive/Colab Notebooks/minutes/data/Round_22_Online_Kickoff_Meeting.vtt\"\n",
        "\n",
        "vtt_to_clean_file(filepath)"
      ],
      "metadata": {
        "id": "ZHOtHSt60g91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d9cfda74-5b4b-4a0d-da5e-68a78d0a3117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clean content is written to file: /content/drive/MyDrive/Colab Notebooks/minutes/data/Round_22_Online_Kickoff_Meeting_2.txt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/minutes/data/Round_22_Online_Kickoff_Meeting_2.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.4. Count the Number of Tokens"
      ],
      "metadata": {
        "id": "FC-sdhOqk7Qr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpenAI GPT-3 is limited by 4,001 tokens it can handle per request which includes both request (i.e., prompt) and response. We will be analyzing how many tokens are in this meeting transcript."
      ],
      "metadata": {
        "id": "HgPybdZ1kqTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_tokens(filename):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "    with open(filename, 'r') as f:\n",
        "        text = f.read()\n",
        "\n",
        "    input_ids = torch.tensor(tokenizer.encode(text)).unsqueeze(0)\n",
        "    num_tokens = input_ids.shape[1]\n",
        "    return num_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "iy9QQE09E3cI",
        "outputId": "c5259411-6d5c-436a-a189-7fde599ed8ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"/content/drive/MyDrive/Colab Notebooks/minutes/data/Round_22_Online_Kickoff_Meeting.txt\"\n",
        "token_count = count_tokens(filename)\n",
        "print(f\"Number of tokens: {token_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "zyPjS1X-FpGh",
        "outputId": "152dbc36-ee34-4974-88df-6fa5ea9bc568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (17537 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tokens: 17537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.5. Break up the Meeting Transcript into chunks of 2000 tokens with an overlap of 100 tokens"
      ],
      "metadata": {
        "id": "1oeA8ivUmql8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be breaking up the Meeting Transcript into chunks of 2,000 tokens with an overlapping 100 tokens to ensure any information is not lost from breaking up the meeting transcript."
      ],
      "metadata": {
        "id": "JNGJroB_mvCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def break_up_file_to_chunks(filename, chunk_size=2000, overlap=100):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "    with open(filename, 'r') as f:\n",
        "        text = f.read()\n",
        "\n",
        "    tokens = tokenizer.encode(text)\n",
        "    num_tokens = len(tokens)\n",
        "    \n",
        "    chunks = []\n",
        "    for i in range(0, num_tokens, chunk_size - overlap):\n",
        "        chunk = tokens[i:i + chunk_size]\n",
        "        chunks.append(chunk)\n",
        "    \n",
        "    return chunks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "1WdNaxfbZUga",
        "outputId": "154a9703-49ad-4462-d84a-fcf1d5bc737a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"/content/drive/MyDrive/Colab Notebooks/minutes/data/Round_22_Online_Kickoff_Meeting.txt\"\n",
        "\n",
        "chunks = break_up_file_to_chunks(filename)\n",
        "for i, chunk in enumerate(chunks):\n",
        "    print(f\"Chunk {i}: {len(chunk)} tokens\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "xMQ4XMAzm05T",
        "outputId": "9e1d9ca9-5658-4411-895c-d75cf494c08b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (17537 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 0: 2000 tokens\n",
            "Chunk 1: 2000 tokens\n",
            "Chunk 2: 2000 tokens\n",
            "Chunk 3: 2000 tokens\n",
            "Chunk 4: 2000 tokens\n",
            "Chunk 5: 2000 tokens\n",
            "Chunk 6: 2000 tokens\n",
            "Chunk 7: 2000 tokens\n",
            "Chunk 8: 2000 tokens\n",
            "Chunk 9: 437 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.6. Validate the break up the Meeting Transcript into chunks of 2000 tokens with an overlap of 100 tokens"
      ],
      "metadata": {
        "id": "rdKOVSLcnH0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
      ],
      "metadata": {
        "id": "oKSR9cpj2JuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(chunks[0][-100:]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "mGd43PG3nvie",
        "outputId": "be8bfe8f-48e6-4e1c-9088-e355a1fbb8c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " So you you can look across all of these open textbooks at once, too. So we will work with you on getting any materials that you've created into an instance of manifold. If they're just ancillary materials that you can download, we'll put them up for download. If you're creating an entirely new open textbook, then we'll help you in getting this into manifold in a really cool way. We even have some training resources in here, including a champions welcome training and kickoff training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(chunks[1][:100]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "hpkKJOqeJjx-",
        "outputId": "d30c8b28-e0f2-4a76-d578-884ffaaf75ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " So you you can look across all of these open textbooks at once, too. So we will work with you on getting any materials that you've created into an instance of manifold. If they're just ancillary materials that you can download, we'll put them up for download. If you're creating an entirely new open textbook, then we'll help you in getting this into manifold in a really cool way. We even have some training resources in here, including a champions welcome training and kickoff training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if tokenizer.decode(chunks[0][-100:]) == tokenizer.decode(chunks[1][:100]):\n",
        "    print('Overlap is Good')\n",
        "else:\n",
        "    print('Overlap is Not Good')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RplGPGmDFEph",
        "outputId": "040d7493-cd98-49d4-b12e-e118d0e22029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overlap is Good\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.7. Set OpenAI API Key"
      ],
      "metadata": {
        "id": "I7ZEq816LCWr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please note that OpenAI's API service is not free, unlike ChatGPT demo. You will need to sign up for a service with them to get an API key, which requires payment information."
      ],
      "metadata": {
        "id": "lyDKuS7CLHJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set an environment variable called “OPEN_API_KEY” and assign a secret API key from OpenAI (https://beta.openai.com/account/api-keys)."
      ],
      "metadata": {
        "id": "1gnYy6NrLJf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = ''"
      ],
      "metadata": {
        "id": "GL4KCDfsK3mD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "91c7fd41-584e-4e71-9ec3-6aa2e85c45e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "NALIE4VOLfEY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "7a62576b-c407-4394-f0dd-bb5df0a53033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.8. Summarize the Meeting Transcript"
      ],
      "metadata": {
        "id": "_LgrIt-an-7T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2.8.1. Summarize the Meeting Transcript one chunk at a time."
      ],
      "metadata": {
        "id": "xBSXqVbJom1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"/content/drive/MyDrive/Colab Notebooks/minutes/data/Round_22_Online_Kickoff_Meeting.txt\"\n",
        "\n",
        "prompt_response = []\n",
        "prompt_tokens = []\n",
        "\n",
        "chunks = break_up_file_to_chunks(filename)\n",
        "for i, chunk in enumerate(chunks):\n",
        "    prompt_request = \"Summarize this meeting transcript: \" + tokenizer.decode(chunks[i])\n",
        "\n",
        "    response = openai.Completion.create(\n",
        "            model=\"text-davinci-003\",\n",
        "            prompt=prompt_request,\n",
        "            temperature=.5,\n",
        "            max_tokens=500,\n",
        "            top_p=1,\n",
        "            frequency_penalty=0,\n",
        "            presence_penalty=0\n",
        "    )\n",
        "    \n",
        "    prompt_response.append(response[\"choices\"][0][\"text\"])\n",
        "    prompt_tokens.append(response[\"usage\"][\"total_tokens\"])"
      ],
      "metadata": {
        "id": "oFfyvbntLxuF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "8fe10ca1-0a92-491c-c5ff-1173dbe22a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (17537 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SsbvQ19pSKw5",
        "outputId": "ff5a8976-8ec6-43b3-a51b-46f2cffd9fbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\". So if you are a new champion and you're trying to figure out what this is all about, you can go into the champions welcome training and get a more detailed look at what this is all about.\\n\\nThis meeting was a kickoff for the recipients of 22 grants. The ALG website was presented, which is the hub for everything related to the grant procedure, including deadlines, reporting guidelines, and online training. ALG also has two homes for OER, Galileo open learning materials and Manifold, which is an interactive platform for open materials. The meeting ended with a Champions Welcome Training and Kickoff Training.\",\n",
              " ' can see me.\\n\\nThis meeting discussed the new ALG website, which will include a mega menu, a grants page, an information center page, a news and events page, and a data page. The ALG website will also link to the repository Galileo Open Learning Materials and Manifold, which makes materials interactive. They also discussed a tracking spreadsheet for all grants, which includes the grant number, purchase order number, round number, fiscal year, type, total award, project lead information, course names and numbers, USG subject area, final report results, annual savings estimate, annual student savings per student, and the semester of implementation. They also discussed a sustainability survey which is used to check in and see if the work done on projects is still ongoing.',\n",
              " \" to help us with the transformation of the textbook because we want to make sure that we have a student perspective on this. So that's sort of our plan and we're very excited to be part of ALG. Excellent. Thank you so much.\\n\\nThis meeting was a discussion of the various ALG projects being undertaken by teams from the University of West Georgia, Clayton State, University of North Georgia, and Georgia Gwinnett College. UWG is transforming a Spanish textbook to have a career-centered focus, Clayton State is transforming a microbiology textbook, UNG is transforming a chemistry textbook to use a specifications-based grading system, and GGC is transforming an introduction to anthropology textbook with the help of student perspectives.\",\n",
              " \" to understand. So we're gonna be making a series of videos and online resources that can be used to get students up to speed on the math and the physics and the engineering concepts that they need to be successful in the course. And then we have a series of assessments that we can use to evaluate the effectiveness of the materials that we're providing. And then we're also gonna be doing some outreach to the high schools and community colleges in the area to try to get them to use these materials to get students up to speed before they get to the university. So that's our goal for the project. Thank you.\\n\\nThis meeting is about a group of five ALG grant recipients from Georgia Gwinnett College, College of Coastal Georgia, Kennesaw State University, Georgia Southern University, Georgia Tech, and Augusta University. Each team is transforming a textbook, creating instructional videos, revising lab materials, and creating custom lab manuals in order to create cost savings for students and more engaging contemporary examples of traditional anthropology concepts. They are all planning to have their projects live by Fall 2021, and they are all working hard to develop comprehensive textbook free packages with digital accessibility and multimedia links.\",\n",
              " ' are focusing on electrical engineering courses. We have a list of courses that we are considering. But the main focus is going to be on the courses that are related to circuit analysis, and especially the circuits that are related to the power system. So the main goal of our project is to develop a set of materials that can be used to teach these courses. We are also going to include some of the simulation tools and the resources that are available in the library and also the online resources that are available. We are also going to develop a set of videos and online resources that can help the students understand the concepts better. So this is the main goal of our project. Thank you.\\n\\nThis meeting was a session for various university teams to present their Affordable Learning Georgia (ALG) Grants. The teams discussed their projects, which are focused on transforming textbooks into digital textbooks or creating affordable learning modules. The projects range from general chemistry to English composition to physical science to circuit analysis and power systems. The teams also discussed their goals, which include reducing costs for students, improving teaching and learning, creating engaging materials, and including multiple representations of concepts.',\n",
              " \" the end is also to make sure that all the funds are accounted for. So that's kind of the basics of how the funding works.\\n\\nThis meeting discussed the Affordable Materials Grant awarded to a team of 5 faculty and a library from Kennesaw State University. The team intends to write a comprehensive and interactive textbook, using open source materials and their own new materials, which will replace the need to purchase a current commercial textbook. The team will also create materials such as instructor solutions, simulations, components, and more. The timeline for the project is one year. The meeting also discussed grant procedures, such as service level agreements, invoices, and reports. Funding for the grant is sent to the institution to complete the project, and is released in two parts, 50% at the beginning and 50% at the end. The funds can be used for personnel, professional development, materials, and more.\",\n",
              " \" breached, then the state can take back any funds that have been dispersed. So it's important to make sure that you're doing what you said you would do. Anything that you have to do to make sure that you're in compliance, you've got to do it.\\n\\nThis transcript is about a meeting discussing the Service Level Agreement between the USG and an institution for a project. It outlines the details of the agreement, such as the start and end dates, how the project funding works, and what to do if something goes wrong. It also emphasizes the importance of the proposal in the agreement and that the institution needs to ensure the statement of work is completed. It also explains that the USG will not allow any line item changes or additional funding, and that any funds dispersed can be taken back if the agreement is breached.\",\n",
              " \" up on the project? Any other questions that you have that you need to ask us? And then the last one is just. Any other comments that you have that you want to share with us. So this is just a way for us to check in with you and make sure that you are on track and that you don't have any questions that are just hanging out in the background.\\n\\nThis is a meeting transcript between two parties in which they discuss the Service Level Agreement (SLA) for a project. They discuss the legal compliance, anti-discrimination clause, amendment process, and payment process. They also discuss the request for proposals, statement of work, and the Board of Regents signatures. They also discuss the process of submitting a semester status report and the use of Google forms and Word documents. Lastly, they discuss the review, adaptation, course redesign, hosting, and other questions that may arise.\",\n",
              " \" this for hours, but I think we've got the gist of what we need to do.\\n\\nThis email is to inform you of the procedures and reporting deadlines for the ALG Grant project. The final report is due on December 19th, 2023, and all relevant materials must be submitted by that date. This includes a Word document version of the final report, data, syllabi, and a team photo (optional). An invoice must also be submitted if applicable. All materials should be sent in a zip file or through Google Drive, Dropbox, or Microsoft OneDrive. Additionally, all grantees are added to the ALG Grantees listserv, which is used to communicate upcoming deadlines and publishing opportunities. If you have any personal questions, please contact Jeff Gallant at jeff.gallant@usg.edu. Dina Anderson should be contacted for SLAs and invoices at dina.anderson@usg.edu. Finally, please bookmark the Grants Information Center page for future reference.\",\n",
              " '\\n\\nThe meeting discussed logistics for upcoming projects, with the speaker reminding everyone to save the grants Information Center link and to reach out with questions. The speaker also mentioned they will be out of town from the 16th to the 2nd, and they will have an away message with instructions. The speaker concluded the meeting by wishing everyone a happy holiday break.']"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tG4qzIMDyGeU",
        "outputId": "7d0e5590-9d53-4a53-a294-6e6b11af7a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2133, 2163, 2154, 2245, 2237, 2191, 2176, 2192, 2213, 516]"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total = 0\n",
        "\n",
        "for e in range(0, len(prompt_tokens)):\n",
        "    total = total + prompt_tokens[e]\n",
        "\n",
        "print(\"Sum of all elements in given list: \", total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zNYP54XJyK6d",
        "outputId": "4c58e634-23da-435f-e6a5-02a7e433c53d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of all elements in given list:  20220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2.8.2. Consolidate the Meeting Transcript Summaries."
      ],
      "metadata": {
        "id": "rL1451Igozer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_request = \"Consoloidate these meeting summaries: \" + str(prompt_response)\n",
        "\n",
        "response = openai.Completion.create(\n",
        "        model=\"text-davinci-003\",\n",
        "        prompt=prompt_request,\n",
        "        temperature=.5,\n",
        "        max_tokens=1000,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )"
      ],
      "metadata": {
        "id": "5eh0cVS0PW5_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "fe5374ba-4658-4f73-bf45-971a2c96b273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "meeting_summary = response[\"choices\"][0][\"text\"]\n",
        "print(meeting_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "yu_cQjLDTAB4",
        "outputId": "f5fcc175-baab-4c4b-aded-a3b6cb9a8217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "This meeting was a kickoff for grants awarded to participants, discussing the Affordable Learning Georgia (ALG) website, and the two repositories, Galileo Open Learning Materials and Manifold, used to store and access open educational resources created through the grants. Participants were introduced to the grant procedures, deadlines, and templates, as well as the ALG grantees listserv. The importance of the Affordable Materials Grants page was emphasized, and the analytics of the repositories, such as most popular downloads and global usage, was discussed. The ALG website will have a mega menu, an About Us section, a grants overview, an Information Center page, and a page for creating resources. It will also have a news and events page, a data page, and a tracking spreadsheet for data. Manifold will be used for interactive materials, and there will be training resources and a student success workshop. The website is expected to be released by the end of January or early February. This meeting is a review of the projects that are being undertaken by the University of West Georgia, Clayton State, the University of North Georgia, and Georgia Gwinnett College. The University of West Georgia is transforming a fourth semester Spanish textbook to be profession/career-centered and connected to a geographical area of the Spanish speaking world. Clayton State is transforming a microbiology textbook for biology majors. The University of North Georgia is transforming a survey of chemistry course for allied health majors, and Georgia Gwinnett College is transforming an introduction to anthropology textbook. All of the projects aim to reduce the cost of textbooks for students and create engaging examples of traditional concepts. This meeting discussed an Affordable Materials Grant project at Kennesaw State University in which a new interactive textbook will be written and developed. The project will include components of simulations and instructors solutions and will replace the need to purchase traditional textbooks. The meeting also discussed grant procedures, such as service level agreements, invoices, and reports, and the funding process, which includes a statement of work, funds for personnel, professional development materials, computer hardware, and software, and 50% of the funding released at the beginning and 50% at the end. This is a meeting transcript between two parties discussing the details of a project agreement. They discuss the legal compliance, anti-discrimination clause, the ability to modify the agreement, the need for signatures from both parties, the need for the agreement to be within federal and state laws, the need for the agreement to be completed in a timely manner, the request for proposals, the statement of work, the process of getting signatures, the need for the invoice to come from the institution, and the need for a semester status report. This meeting discussed the final report for the ALG grants, which is due on December 19th. It outlined the components of the final report, such as the Word document version, data, syllabi, and photos. It also discussed upcoming reporting deadlines and the ALGGRANTEES listserv. The meeting concluded with instructions to save the Grants Information Center link and to send SLAs and invoices to Dina Anderson. This meeting was about making sure everyone had the necessary information for upcoming projects. The administrator will be out from the 16th to the 2nd, so documents should be sent to them in the meantime. The meeting concluded with a reminder to reach out with any questions and well wishes for a happy holiday break.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.9. Get Action Items from Meeting Transcript"
      ],
      "metadata": {
        "id": "MRwpgJ1gpPhL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2.9.1. Get Action Items from the Meeting Transcript one chunk at a time."
      ],
      "metadata": {
        "id": "nhZfit-nplpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"/content/drive/MyDrive/Colab Notebooks/minutes/data/Round_22_Online_Kickoff_Meeting.txt\"\n",
        "\n",
        "action_response = []\n",
        "action_tokens = []\n",
        "\n",
        "chunks = break_up_file_to_chunks(filename)\n",
        "for i, chunk in enumerate(chunks):\n",
        "    prompt_request = \"Provide a list of action items with a due date from the provided meeting transcript text: \" + tokenizer.decode(chunks[i])\n",
        "\n",
        "    response = openai.Completion.create(\n",
        "            model=\"text-davinci-003\",\n",
        "            prompt=prompt_request,\n",
        "            temperature=.5,\n",
        "            max_tokens=500,\n",
        "            top_p=1,\n",
        "            frequency_penalty=0,\n",
        "            presence_penalty=0\n",
        "    )\n",
        "    \n",
        "    action_response.append(response[\"choices\"][0][\"text\"])\n",
        "    action_tokens.append(response[\"usage\"][\"total_tokens\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "JvHJV8KeUzeS",
        "outputId": "460fe225-0c30-4d5b-dd56-5f6f37fdfe3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (17537 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ServiceUnavailableError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mServiceUnavailableError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-160-bc0d8903dbe4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprompt_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Provide a list of action items with a due date from the provided meeting transcript text: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     response = openai.Completion.create(\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-davinci-003\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt_request\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/api_resources/completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         )\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             return (\n\u001b[0;32m--> 619\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    620\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m503\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             raise error.ServiceUnavailableError(\n\u001b[0m\u001b[1;32m    663\u001b[0m                 \u001b[0;34m\"The server is overloaded or not ready yet.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mServiceUnavailableError\u001b[0m: The server is overloaded or not ready yet."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(action_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZNzPeL8SVJSG",
        "outputId": "50397550-c3ba-4632-b4d6-5d4d21c43162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\". So if you can't make it to one of our kickoff meetings, you can always watch this one. Action Items:\\n\\n1. Introduce yourself to the ALG listserv - Due Date: Immediately \\n2. Bookmark the ALG Grants page - Due Date: Immediately \\n3. Submit a report using the ALG templates and forms - Due Date: December 19th \\n4. Convert static files into Manifold texts - Due Date: As needed \\n5. Watch the ALG Champions Welcome Training and Kickoff Training - Due Date: Immediately\", ', can you please turn on your camera?\\n\\nAction Items:\\n-Put any ancillary materials up for download (Due Date: ASAP)\\n-Help create an entirely new open textbook and get it into Manifold (Due Date: ASAP)\\n-Champions Welcome Training and Kickoff Training (Due Date: ASAP)\\n-Create Student Success Workshop (Due Date: ASAP)\\n-Work with Web Person and Marketing Coordinator to create new ALG website (Due Date: End of January/Beginning of February)\\n-Create Accessibility Guides (Due Date: ASAP)\\n-Create Open Licensing Resources (Due Date: ASAP)\\n-Create a new way to announce news and events (Due Date: ASAP)\\n-Create a Data Page (Due Date: End of January/Beginning of February)\\n-Create ALG Tracking Spreadsheet (Due Date: ASAP)\\n-Contact Project Leads Yearly for Sustainability Survey (Due Date: Ongoing)', \" to help us with this, and we're going to have them create some of the content, so we're excited about that. We're also going to be creating a lot of interactive activities and simulations, and we're going to be creating a lot of videos. We're going to be creating a lot of multimedia content, so that's our plan. And we're going to be doing this over the next two semesters, so that's what we're up to. Great. Thank you so much.\\n\\nAction Items\\n\\n1. Begin hiring process for Program Manager (January)\\n2. Create demonstration videos for laboratory techniques (by February)\\n3. Develop group work activities (by March)\\n4. Redevelop laboratory component (by April)\\n5. Create interactive activities and simulations (by May)\\n6. Create videos and multimedia content (by June)\", \" to understand, so our goal is to make it more accessible, more understandable. And so we're gonna be making a series of videos and online resources that will help them with the prerequisites, but also help them understand the material. We're also gonna be doing some experiments and bringing in some other faculty members to help us with the experiments. And then also looking at some of the data analysis and visualization, so that they can better understand the material. We're hoping to have this done by the end of the summer, so that we can have it ready for the fall semester.\\n\\nAction Items\\n\\n1. Hire students to write vignettes and case studies (Due Date: ASAP)\\n2. Develop instructional videos with annotations (Due Date: ASAP)\\n3. Rewrite and add laboratory materials (Due Date: ASAP)\\n4. Create new custom lab manuals (Due Date: Fall)\\n5. Develop comprehensive textbook-free package (Due Date: Fall)\\n6. Create materials that pass digital accessibility (Due Date: Fall)\\n7. Develop math primer, videos, and online resources (Due Date: End of Summer)\\n8. Conduct experiments and bring in faculty members to help (Due Date: End of Summer)\\n9. Analyze data and visualize material (Due Date: End of Summer)\", \" are looking at developing an online course for the junior level course in our electrical engineering department, which is basically the course on fluid mechanics. So the main goal of this project is to develop a course that's more engaging for the students and also to make sure that the students have the prerequisites to be able to take the course. So we are going to develop the course in such a way that the students can take the course and learn the material in a more engaging way. So that's the main goal of this project.\\n\\nAction Items:\\n\\n1. Contact Amy Battles and share materials - Due Date: ASAP\\n2. Create math primer with videos and online resources to get students up to speed - Due Date: 2 semesters\\n3. Make material accessible to students on different levels - Due Date: 2 semesters\\n4. Create digital textbook for Chem 1212 - Due Date: Fall 2022\\n5. Create Atlas for Histology and workbook - Due Date: TBD\\n6. Create affordable learning modules to replace textbooks - Due Date: Fall 2021\\n7. Hire student assistants for usability testing - Due Date: TBD\\n8. Review materials from Diversity and Inclusion Office - Due Date: TBD\\n9. Create OER resources for Calculus 1 - Due Date: TBD\\n10. Create problem sets and projects for Calculus 1 - Due Date: TBD\\n11. Create instructional videos for Calculus 1 - Due Date: TBD\\n12. Develop online course for Junior level Electrical Engineering course in Fluid Mechanics - Due Date: TBD\", \" the beginning and 50% at the end is also to make sure that the work is done, that the project is completed, that the work is done, and then the funds are released. So that's kind of the background of how funding works in the grant.\\n\\nAction Items:\\n\\n1. Recruit a graduate student assistant to help with the materials by August 1st \\n\\n2. Write a new textbook and use open source materials by October 1st \\n\\n3. Create instructor solutions by December 1st \\n\\n4. Replace broken links and revise by adding new text as necessary by January 1st \\n\\n5. Create PDF version of the text by February 1st \\n\\n6. Convert previously written OER for Spanish one and two into an interactive ebook with interactions embedded in the text by March 1st \\n\\n7. Update multiple choice questions, essays, and discussions by April 1st \\n\\n8. Find OER with adaptive learning software and 1st year writing by May 1st \\n\\n9. Use visualization and game development language and environment process both courses by June 1st \\n\\n10. Update grant procedures, service level agreements, invoices, and reports by July 1st\", \" breached, then there is a process that we have to go through. It's not a punitive process. It's just a process to make sure that everybody is on the same page and that we can move forward.\\n\\nAction Items: \\n1. Reach out to business and grants office to understand institutional rules and regulations - Due Date: ASAP\\n2. Ensure that the start date and end date on the service level agreement (SLA) are correct - Due Date: ASAP\\n3. Contact USG if any changes need to be made to the SLA - Due Date: ASAP\\n4. Contact USG if any issues arise that could affect the project - Due Date: ASAP\\n5. Ensure that all legal and compliance requirements for the SLA are met - Due Date: ASAP\", \" up that you're doing? Any questions about the project? Any questions about the budget? Any questions about the timeline? Any questions about the team? Any questions about the software? And if you have any questions about the SLA, that's a great place to put it.\\n\\nAction Items: \\n1. Draft SLAs and send to project leads by Monday - Due Date: Monday\\n2. Reach out to business or grants office if something looks weird - Due Date: ASAP\\n3. Once SLAs are fully executed, send to institution - Due Date: ASAP\\n4. Institution should send first invoice to USG - Due Date: ASAP\\n5. Check in every semester with semester status report - Due Date: Spring 2023\\n6. Use three digit number in notification of award and SLA - Due Date: ASAP\\n7. List team members in semester status report - Due Date: Spring 2023\\n8. Email Word document of materials to USG - Due Date: ASAP\\n9. Check in on review, adaptation, materials, course redesign, hosting, budget, timeline, team, software, and SLA - Due Date: Spring 2023\", \" this kind of stuff in the first meeting, but I think it's better if we just get it done and out of the way.\\n\\nAction Items:\\n-Send SLAs and invoices to Dina Anderson (dina.anderson@usg.edu) by December 14th (Monday)\\n-Submit final report to Grants Information Center by December 19th\\n-Submit semester status report for Spring 2023 by May 15th\\n-Submit semester status report for Summer 2023 by August 14th\\n-Submit semester status report for Fall 2023 by December 18th\", '\\n\\nAction Items: \\n1. Save the Grants Information Center link - Due Date: N/A \\n2. Karen to send an e-mail about timeline - Due Date: ASAP \\n3. Everyone to reach out whenever they have a question - Due Date: N/A \\n4. Send documents to administrator - Due Date: Between 16th and 2nd']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2.9.2. Consolidate the Meeting Transcript Action Items."
      ],
      "metadata": {
        "id": "_Od7s1fwpdy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_request = \"Consoloidate these meeting action items, but exclude action items with Due Date of Immediately: \" + str(action_response)\n",
        "\n",
        "response = openai.Completion.create(\n",
        "        model=\"text-davinci-003\",\n",
        "        prompt=prompt_request,\n",
        "        temperature=.5,\n",
        "        max_tokens=500,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "\n",
        "action_tokens= response[\"usage\"][\"total_tokens\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "MISAIRbJWamn",
        "outputId": "9c430906-9c8c-400d-a69b-43af077960e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-153-dae831bd5c3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprompt_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Consoloidate these meeting action items, but exclude action items with Due Date of Immediately: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m response = openai.Completion.create(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-davinci-003\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt_request\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/api_resources/completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     ) -> Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], bool, str]:\n\u001b[0;32m--> 216\u001b[0;31m         result = self.request_raw(\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0m_thread_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             result = _thread_context.session.request(\n\u001b[0m\u001b[1;32m    517\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m                 \u001b[0mabs_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m             httplib_response = self._make_request(conn, method, url,\n\u001b[0m\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "meeting_action_items = response[\"choices\"][0][\"text\"]\n",
        "print(meeting_action_items)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "5b3aowAFWjdY",
        "outputId": "a1dea41d-3849-402d-d92e-2893e64cfe5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Consolidated Action Items:\n",
            "-Put any ancillary materials up for download (Due Date: ASAP)\n",
            "-Help create an entirely new open textbook and get it into Manifold (Due Date: ASAP)\n",
            "-Champions Welcome Training and Kickoff Training (Due Date: ASAP)\n",
            "-Create Student Success Workshop (Due Date: ASAP)\n",
            "-Work with Web Person and Marketing Coordinator to create new ALG website (Due Date: End of January/Beginning of February)\n",
            "-Create Accessibility Guides (Due Date: ASAP)\n",
            "-Create Open Licensing Resources (Due Date: ASAP)\n",
            "-Create a new way to announce news and events (Due Date: ASAP)\n",
            "-Create a Data Page (Due Date: End of January/Beginning of February)\n",
            "-Create ALG Tracking Spreadsheet (Due Date: ASAP)\n",
            "-Contact Project Leads Yearly for Sustainability Survey (Due Date: Ongoing)\n",
            "-Begin hiring process for Program Manager (January)\n",
            "-Create demonstration videos for laboratory techniques (by February)\n",
            "-Develop group work activities (by March)\n",
            "-Redevelop laboratory component (by April)\n",
            "-Create interactive activities and simulations (by May)\n",
            "-Create videos and multimedia content (by June)\n",
            "-Contact Amy Battles and share materials - Due Date: ASAP\n",
            "-Create math primer with videos and online resources to get students up to speed - Due Date: 2 semesters\n",
            "-Make material accessible to students on different levels - Due Date: 2 semesters\n",
            "-Create digital textbook for Chem 1212 - Due Date: Fall 2022\n",
            "-Create Atlas for Histology and workbook - Due Date: TBD\n",
            "-Create affordable learning modules to replace textbooks - Due Date: Fall 2021\n",
            "-Hire student assistants for usability testing - Due Date: TBD\n",
            "-Review materials from Diversity and Inclusion Office - Due Date: TBD\n",
            "-Create OER resources for Calculus 1 - Due Date: TBD\n",
            "-Create problem sets and projects for Calculus 1 - Due Date: TBD\n",
            "-Create instructional videos for Calculus 1 - Due Date: TBD\n",
            "-Develop online course for Junior level Electrical Engineering course in Fluid Mechanics - Due Date: TBD\n",
            "-Recruit a graduate student assistant to help with the materials by August 1st \n",
            "-Write a new textbook and use open source materials by October 1st \n",
            "-Create instructor solutions by December 1st \n",
            "-\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response[\"usage\"][\"prompt_tokens\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "G3IG4OdOmZ5n",
        "outputId": "57e7b7c4-43f3-4eef-b6ce-fecb08d1f695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2030"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response[\"usage\"][\"completion_tokens\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "l8w402OGnGCZ",
        "outputId": "b5379619-a317-4124-dd37-526780b2d1af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response[\"usage\"][\"total_tokens\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hBJ2kbRBnJGY",
        "outputId": "289eeeb6-2107-42d6-bd16-7f6b18326df1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2530"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    }
  ]
}