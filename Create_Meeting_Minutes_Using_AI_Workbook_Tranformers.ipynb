{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWAf0eEJUfd/TwXAC3wApz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sungkim11/ai-playground/blob/main/Create_Meeting_Minutes_Using_AI_Workbook_Tranformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create a Meeting Minute using OpenAI's GPT-3 from both Microsoft Team's Meeting Transcript or Zoom's Meeting Transcript (Transformers)"
      ],
      "metadata": {
        "id": "vC0t_IHQgV6-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is my endeavor to replicate upcoming Microsoft Team Premium feature to create meeting notes using AI."
      ],
      "metadata": {
        "id": "N7R-tsFJgr7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Prerequisites"
      ],
      "metadata": {
        "id": "4b_S-B5jg7f2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following are prerequisites for this tutorial:\n",
        "\n",
        "- Python Package: openai\n",
        "- Python Package: torch and transformers"
      ],
      "metadata": {
        "id": "DfTwEED_g_kb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.1. Python Packages"
      ],
      "metadata": {
        "id": "hEIroo2BhEzH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####1.1.1. Install Python Packages"
      ],
      "metadata": {
        "id": "z8G98yU0z8y_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "-uNn49xIzMq7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e5a72f89-95bb-4f61-dfa1-e3a91bc8a8e9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile requirements.txt\n",
        "openai\n",
        "torch==1.13.1+cu116\n",
        "transformers==4.26.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "fdJwUNoszSIp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "outputId": "7c6d83da-938e-4432-88c2-1b84051ffb24"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (0.26.5)\n",
            "Requirement already satisfied: torch==1.13.1+cu116 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (1.13.1+cu116)\n",
            "Requirement already satisfied: transformers==4.26.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 3)) (4.26.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1+cu116->-r requirements.txt (line 2)) (4.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.1->-r requirements.txt (line 3)) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.1->-r requirements.txt (line 3)) (0.13.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.1->-r requirements.txt (line 3)) (2.25.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.1->-r requirements.txt (line 3)) (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.1->-r requirements.txt (line 3)) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.1->-r requirements.txt (line 3)) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.1->-r requirements.txt (line 3)) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.1->-r requirements.txt (line 3)) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.1->-r requirements.txt (line 3)) (23.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from openai->-r requirements.txt (line 1)) (3.8.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.26.1->-r requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.26.1->-r requirements.txt (line 3)) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.26.1->-r requirements.txt (line 3)) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.26.1->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai->-r requirements.txt (line 1)) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai->-r requirements.txt (line 1)) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai->-r requirements.txt (line 1)) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai->-r requirements.txt (line 1)) (2.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai->-r requirements.txt (line 1)) (22.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai->-r requirements.txt (line 1)) (6.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Code"
      ],
      "metadata": {
        "id": "dzLhnP--hOxp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colab code to prettify text output."
      ],
      "metadata": {
        "id": "lGFFGcY1tasJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "Ow3tBDBfseRE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f94880a8-846c-4500-d576-e1756118bd0d"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.1. Import Python Packages"
      ],
      "metadata": {
        "id": "WmRPmprK0GM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import platform\n",
        "import os\n",
        "\n",
        "import openai\n",
        "\n",
        "import re\n",
        "from os.path import splitext, exists\n",
        "\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "print('Python: ', platform.python_version())\n",
        "print('re: ', re.__version__)\n",
        "print('torch: ', torch.__version__)\n",
        "print('transformers: ', transformers.__version__)"
      ],
      "metadata": {
        "id": "0Zs3zeEy0HXX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "0fe7d7c4-f403-4580-a4f3-71fb6a489cf4"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python:  3.8.10\n",
            "re:  2.2.1\n",
            "torch:  1.13.1+cu116\n",
            "transformers:  4.26.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.2. Mount Storage - Google Drive"
      ],
      "metadata": {
        "id": "_5EJ0NJHzmxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Tx1d61zFzkMT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a8116f8c-c0b4-450e-8285-3ead7d3239a6"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.3. Clean Meeting Transcript from either Microsoft Team or Zoom, encoded as WEBVTT file."
      ],
      "metadata": {
        "id": "qj6-FtO2zsb8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The meeting transcript is encoded as follows:\n",
        "\n",
        "    WEBVTT\n",
        "    \n",
        "    03951482-18bc-403b-9a4f-9d2699587f03/65-1\n",
        "    00:00:08.885 --> 00:00:13.589\n",
        "    transcription making sure that\n",
        "    the transcription does work. Yep"
      ],
      "metadata": {
        "id": "jvuyPQvdiTq1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is not usually problem with ChatGPT, but OpenAI GPT-3 API charges by a token and we want to minimize the number of tokens sending to it. We will need to remove all lines that is not a transcript."
      ],
      "metadata": {
        "id": "dW6bAm4WjRTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These two functions clean up .vtt file and then produce a clean text file with the same filename with an extension of .txt."
      ],
      "metadata": {
        "id": "5I6qHWX9kJb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_webvtt(filepath: str) -> str:\n",
        "    \"\"\"Clean up the content of a subtitle file (vtt) to a string\n",
        "\n",
        "    Args:\n",
        "        filepath (str): path to vtt file\n",
        "\n",
        "    Returns:\n",
        "        str: clean content\n",
        "    \"\"\"\n",
        "    # read file content\n",
        "    with open(filepath, \"r\", encoding=\"utf-8\") as fp:\n",
        "        content = fp.read()\n",
        "\n",
        "    # remove header & empty lines\n",
        "    lines = [line.strip() for line in content.split(\"\\n\") if line.strip()]\n",
        "    lines = lines[1:] if lines[0].upper() == \"WEBVTT\" else lines\n",
        "\n",
        "    # remove indexes\n",
        "    lines = [lines[i] for i in range(len(lines)) if not lines[i].isdigit()]\n",
        "\n",
        "    # remove tcode\n",
        "    #pattern = re.compile(r'^[0-9:.]{12} --> [0-9:.]{12}')\n",
        "    pattern = r'[a-f\\d]{8}-[a-f\\d]{4}-[a-f\\d]{4}-[a-f\\d]{4}-[a-f\\d]{12}\\/\\d+-\\d'\n",
        "    lines = [lines[i] for i in range(len(lines))\n",
        "             if not re.match(pattern, lines[i])]\n",
        "\n",
        "    # remove timestamps\n",
        "    pattern = r\"^\\d{2}:\\d{2}:\\d{2}.\\d{3}.*\\d{2}:\\d{2}:\\d{2}.\\d{3}$\"\n",
        "    lines = [lines[i] for i in range(len(lines))\n",
        "             if not re.match(pattern, lines[i])]\n",
        "\n",
        "    content = \" \".join(lines)\n",
        "\n",
        "    # remove duplicate spaces\n",
        "    pattern = r\"\\s+\"\n",
        "    content = re.sub(pattern, r\" \", content)\n",
        "\n",
        "    # add space after punctuation marks if it doesn't exist\n",
        "    pattern = r\"([\\.!?])(\\w)\"\n",
        "    content = re.sub(pattern, r\"\\1 \\2\", content)\n",
        "\n",
        "    return content\n",
        "\n",
        "\n",
        "def vtt_to_clean_file(file_in: str, file_out=None, **kwargs) -> str:\n",
        "    \"\"\"Save clean content of a subtitle file to text file\n",
        "\n",
        "    Args:\n",
        "        file_in (str): path to vtt file\n",
        "        file_out (None, optional): path to text file\n",
        "        **kwargs (optional): arguments for other parameters\n",
        "            - no_message (bool): do not show message of result.\n",
        "                                 Default is False\n",
        "\n",
        "    Returns:\n",
        "        str: path to text file\n",
        "    \"\"\"\n",
        "    # set default values\n",
        "    no_message = kwargs.get(\"no_message\", False)\n",
        "    if not file_out:\n",
        "        filename = splitext(file_in)[0]\n",
        "        file_out = \"%s.txt\" % filename\n",
        "        i = 0\n",
        "        while exists(file_out):\n",
        "            i += 1\n",
        "            file_out = \"%s_%s.txt\" % (filename, i)\n",
        "\n",
        "    content = clean_webvtt(file_in)\n",
        "    with open(file_out, \"w+\", encoding=\"utf-8\") as fp:\n",
        "        fp.write(content)\n",
        "    if not no_message:\n",
        "        print(\"clean content is written to file: %s\" % file_out)\n",
        "\n",
        "    return file_out"
      ],
      "metadata": {
        "id": "d1T3XitJ1Z58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6c399063-e9f6-4138-968f-a6fcbcb82319"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"/content/drive/MyDrive/Colab Notebooks/minutes/data/Round_22_Online_Kickoff_Meeting.vtt\"\n",
        "\n",
        "vtt_to_clean_file(filepath)"
      ],
      "metadata": {
        "id": "ZHOtHSt60g91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d9cfda74-5b4b-4a0d-da5e-68a78d0a3117"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clean content is written to file: /content/drive/MyDrive/Colab Notebooks/minutes/data/Round_22_Online_Kickoff_Meeting_2.txt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/minutes/data/Round_22_Online_Kickoff_Meeting_2.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.4. Count the Number of Tokens"
      ],
      "metadata": {
        "id": "FC-sdhOqk7Qr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpenAI GPT-3 is limited by 4,001 tokens it can handle per request which includes both request (i.e., prompt) and response. We will be analyzing how many tokens are in this meeting transcript."
      ],
      "metadata": {
        "id": "HgPybdZ1kqTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_tokens(filename):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "    with open(filename, 'r') as f:\n",
        "        text = f.read()\n",
        "\n",
        "    input_ids = torch.tensor(tokenizer.encode(text)).unsqueeze(0)\n",
        "    num_tokens = input_ids.shape[1]\n",
        "    return num_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "iy9QQE09E3cI",
        "outputId": "c5259411-6d5c-436a-a189-7fde599ed8ec"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"/content/drive/MyDrive/Colab Notebooks/minutes/data/Round_22_Online_Kickoff_Meeting.txt\"\n",
        "token_count = count_tokens(filename)\n",
        "print(f\"Number of tokens: {token_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "zyPjS1X-FpGh",
        "outputId": "152dbc36-ee34-4974-88df-6fa5ea9bc568"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (17537 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tokens: 17537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.5. Break up the Meeting Transcript into chunks of 2000 tokens with an overlap of 100 tokens"
      ],
      "metadata": {
        "id": "1oeA8ivUmql8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be breaking up the Meeting Transcript into chunks of 2,000 tokens with an overlapping 100 tokens to ensure any information is not lost from breaking up the meeting transcript."
      ],
      "metadata": {
        "id": "JNGJroB_mvCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def break_up_file_to_chunks(filename, chunk_size=2000, overlap=100):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "    with open(filename, 'r') as f:\n",
        "        text = f.read()\n",
        "\n",
        "    tokens = tokenizer.encode(text)\n",
        "    num_tokens = len(tokens)\n",
        "    \n",
        "    chunks = []\n",
        "    for i in range(0, num_tokens, chunk_size - overlap):\n",
        "        chunk = tokens[i:i + chunk_size]\n",
        "        chunks.append(chunk)\n",
        "    \n",
        "    return chunks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "1WdNaxfbZUga",
        "outputId": "154a9703-49ad-4462-d84a-fcf1d5bc737a"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"/content/drive/MyDrive/Colab Notebooks/minutes/data/Round_22_Online_Kickoff_Meeting.txt\"\n",
        "\n",
        "chunks = break_up_file_to_chunks(filename)\n",
        "for i, chunk in enumerate(chunks):\n",
        "    print(f\"Chunk {i}: {len(chunk)} tokens\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "xMQ4XMAzm05T",
        "outputId": "9e1d9ca9-5658-4411-895c-d75cf494c08b"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (17537 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 0: 2000 tokens\n",
            "Chunk 1: 2000 tokens\n",
            "Chunk 2: 2000 tokens\n",
            "Chunk 3: 2000 tokens\n",
            "Chunk 4: 2000 tokens\n",
            "Chunk 5: 2000 tokens\n",
            "Chunk 6: 2000 tokens\n",
            "Chunk 7: 2000 tokens\n",
            "Chunk 8: 2000 tokens\n",
            "Chunk 9: 437 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.6. Validate the break up the Meeting Transcript into chunks of 2000 tokens with an overlap of 100 tokens"
      ],
      "metadata": {
        "id": "rdKOVSLcnH0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(chunks[0][-100:]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "mGd43PG3nvie",
        "outputId": "be8bfe8f-48e6-4e1c-9088-e355a1fbb8c4"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " So you you can look across all of these open textbooks at once, too. So we will work with you on getting any materials that you've created into an instance of manifold. If they're just ancillary materials that you can download, we'll put them up for download. If you're creating an entirely new open textbook, then we'll help you in getting this into manifold in a really cool way. We even have some training resources in here, including a champions welcome training and kickoff training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(chunks[1][:100]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "hpkKJOqeJjx-",
        "outputId": "d30c8b28-e0f2-4a76-d578-884ffaaf75ab"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " So you you can look across all of these open textbooks at once, too. So we will work with you on getting any materials that you've created into an instance of manifold. If they're just ancillary materials that you can download, we'll put them up for download. If you're creating an entirely new open textbook, then we'll help you in getting this into manifold in a really cool way. We even have some training resources in here, including a champions welcome training and kickoff training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if tokenizer.decode(chunks[0][-100:]) == tokenizer.decode(chunks[1][:100]):\n",
        "    print('Overlap is Good')\n",
        "else:\n",
        "    print('Overlap is Not Good')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RplGPGmDFEph",
        "outputId": "040d7493-cd98-49d4-b12e-e118d0e22029"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overlap is Good\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.7. Set OpenAI API Key"
      ],
      "metadata": {
        "id": "I7ZEq816LCWr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please note that OpenAI's API service is not free, unlike ChatGPT demo. You will need to sign up for a service with them to get an API key, which requires payment information."
      ],
      "metadata": {
        "id": "lyDKuS7CLHJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set an environment variable called “OPEN_API_KEY” and assign a secret API key from OpenAI (https://beta.openai.com/account/api-keys)."
      ],
      "metadata": {
        "id": "1gnYy6NrLJf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = 'paste your openai api key here'"
      ],
      "metadata": {
        "id": "GL4KCDfsK3mD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "86680ba4-9f7d-4bc4-9641-e0995130eeb4"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "NALIE4VOLfEY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e308d131-91fd-4e75-a249-aac40478db11"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.8. Summarize the Meeting Transcript"
      ],
      "metadata": {
        "id": "_LgrIt-an-7T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2.8.1. Summarize the Meeting Transcript one chunk at a time."
      ],
      "metadata": {
        "id": "xBSXqVbJom1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"/content/drive/MyDrive/Colab Notebooks/minutes/data/Round_22_Online_Kickoff_Meeting.txt\"\n",
        "\n",
        "prompt_response = []\n",
        "\n",
        "chunks = break_up_file_to_chunks(filename)\n",
        "for i, chunk in enumerate(chunks):\n",
        "    prompt_request = \"Summarize this meeting transcript: \" + tokenizer.decode(chunks[i])\n",
        "\n",
        "    response = openai.Completion.create(\n",
        "            model=\"text-davinci-003\",\n",
        "            prompt=prompt_request,\n",
        "            temperature=.5,\n",
        "            max_tokens=500,\n",
        "            top_p=1,\n",
        "            frequency_penalty=0,\n",
        "            presence_penalty=0\n",
        "    )\n",
        "    \n",
        "    prompt_response.append(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "id": "oFfyvbntLxuF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "08fdb903-9799-4bc2-f9c3-d4ed13a2eade"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (17537 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SsbvQ19pSKw5",
        "outputId": "62cb407a-b843-4390-b379-69f2249bf4a1"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['. So if you want to learn more about manifold and how to use it, you can check out these two videos.\\n\\nThis meeting was a kickoff for grants awarded to participants, discussing the Affordable Learning Georgia (ALG) website, and the two repositories, Galileo Open Learning Materials and Manifold, used to store and access open educational resources created through the grants. Participants were introduced to the grant procedures, deadlines, and templates, as well as the ALG grantees listserv. The importance of the Affordable Materials Grants page was emphasized, and the analytics of the repositories, such as most popular downloads and global usage, was discussed. Lastly, the benefits of Manifold, such as interactive text, annotations, highlights, and searching, were detailed.',\n",
              " ', can you hear me?\\n\\nThis meeting was about the new ALG website, which is the home page for Affordable Learning Georgia. It will have a mega menu, an About Us section, a grants overview, an Information Center page, and a page for creating resources. It will also have a news and events page, a data page, and a tracking spreadsheet for data. The ALG website will also link to Galileo Open Learning Materials, which is the first repository and connects to all library resources. Manifold will be used for interactive materials, and there will be training resources and a student success workshop. The website is expected to be released by the end of January or early February.',\n",
              " \" to be our research assistants, and they will be helping us to find some of those engaging examples. So that's kind of our plan. We are still in the early stages of planning, but we're hoping that we'll be able to create something that's really useful for students. Great. Thank you so much.\\n\\nThis meeting is a review of the projects that are being undertaken by the University of West Georgia, Clayton State, the University of North Georgia, and Georgia Gwinnett College. The University of West Georgia is transforming a fourth semester Spanish textbook to be profession/career-centered and connected to a geographical area of the Spanish speaking world. Clayton State is transforming a microbiology textbook for biology majors. The University of North Georgia is transforming a survey of chemistry course for allied health majors, and Georgia Gwinnett College is transforming an introduction to anthropology textbook. All of the projects aim to reduce the cost of textbooks for students and create engaging examples of traditional concepts.\",\n",
              " \". So what we're doing is we're creating a series of videos and online resources that can help them understand the basic concepts of fluid mechanics and engineering in general. And then we're also gonna be creating a series of videos that are more specific to the course that they're taking. So that's the overview of what we're doing. Uh, yeah, that's it. Thank you.\\n\\nThis meeting was attended by 8 teams from 8 different universities in Georgia. Each team discussed their project that was funded by the ALG grant. The projects include transforming an introduction to anthropology textbook, creating custom lab manuals for introductory biology sequence, creating a textbook free package for an Asian Studies course, transforming textbooks and lab materials for autonomous vehicle sensors and PLC programmable logic controllers, revising and expanding proprietary materials for English 1101 and 1102, creating a math primer with videos and online resources to help students understand basic concepts of fluid mechanics, and creating videos and online resources to help students understand engineering courses. Each team discussed their timeline and goals for their project and thanked the ALG grant for their support.\",\n",
              " \" are focusing on engineering mathematics and especially fluid mechanics. We see a lot of the students that drop the course or fail or because of not having enough prerequisites. And so our goal of this is to basically make a math primer, a series of videos and online resources that can get them up to speed during the class. We've we've basically given to them for one or two semesters. The feedback we've gotten that it's still too difficult. Some of the material that we're providing is still too hard for some of these students. And it makes sense. Some of them have failed calculus a few times and they're basically just getting through. And so this semester, we're gonna keep on making in the videos on the topics and try to. Makes the material broad levels, so you can have those. Basically students that are on different levels, and I'm gonna contact you, Amy battles, because it sounds like you working on something for physics, so maybe we can share some materials. So I'm glad we're doing this session. Thank you. Very cool.\\n\\nThis meeting was about several teams from different universities proposing projects for the Affordable Learning Georgia grant. The projects range from creating digital textbooks for general chemistry, creating an Atlas for Histology, creating affordable learning modules to replace textbooks with a focus on diversity and inclusion, and creating math primers and video resources for engineering mathematics, especially fluid mechanics. The goal of all of the projects is to reduce the cost for students, improve the teaching and learning of the courses, and make the materials more accessible.\",\n",
              " \" the beginning, 50% at the end also prevents any kind of misuse of funds. So that's why we do it this way.\\n\\nThis meeting discussed an Affordable Materials Grant project at Kennesaw State University in which a new interactive textbook will be written and developed. The project will include components of simulations and instructors solutions and will replace the need to purchase traditional textbooks. The meeting also discussed grant procedures, such as service level agreements, invoices, and reports, and the funding process, which includes a statement of work, funds for personnel, professional development materials, computer hardware, and software, and 50% of the funding released at the beginning and 50% at the end.\",\n",
              " \" terminated, it's just a standard termination agreement. So that is the service level agreement.\\n\\nThis transcript is about the USG's Service Level Agreement, which is an agreement between the USG and an institution that defines how a project will be funded and completed. It outlines the start and end dates, the budget, personnel, and impact of the project. It also explains what to do if something goes wrong, such as contacting the USG to amend the agreement or evaluate the amount of work done. The agreement also includes legal compliance and termination agreements.\",\n",
              " \" up that you need to do? That's all we're asking. We just want to make sure that you're on track and that you're able to get to the end goal.\\n\\nThis is a meeting transcript between two parties discussing the details of a project agreement. They discuss the legal compliance, anti-discrimination clause, the ability to modify the agreement, the need for signatures from both parties, the need for the agreement to be within federal and state laws, the need for the agreement to be completed in a timely manner, the request for proposals, the statement of work, the process of getting signatures, the need for the invoice to come from the institution, and the need for a semester status report.\",\n",
              " \" this for hours. But I think that's enough for today.\\n\\nThis meeting discussed the final report for the ALG grants, which is due on December 19th. It outlined the components of the final report, such as the Word document version, data, syllabi, and photos. It also discussed upcoming reporting deadlines and the ALGGRANTEES listserv. The meeting concluded with instructions to save the Grants Information Center link and to send SLAs and invoices to Dina Anderson.\",\n",
              " '\\n\\nThis meeting was about making sure everyone had the necessary information for upcoming projects. The administrator will be out from the 16th to the 2nd, so documents should be sent to them in the meantime. The meeting concluded with a reminder to reach out with any questions and well wishes for a happy holiday break.']"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2.8.2. Consolidate the Meeting Transcript Summaries."
      ],
      "metadata": {
        "id": "rL1451Igozer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_request = \"Consoloidate these meeting summaries: \" + str(prompt_response)\n",
        "\n",
        "response = openai.Completion.create(\n",
        "        model=\"text-davinci-003\",\n",
        "        prompt=prompt_request,\n",
        "        temperature=.5,\n",
        "        max_tokens=1000,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )"
      ],
      "metadata": {
        "id": "5eh0cVS0PW5_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "fe5374ba-4658-4f73-bf45-971a2c96b273"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "meeting_summary = response[\"choices\"][0][\"text\"]\n",
        "print(meeting_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "yu_cQjLDTAB4",
        "outputId": "f5fcc175-baab-4c4b-aded-a3b6cb9a8217"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "This meeting was a kickoff for grants awarded to participants, discussing the Affordable Learning Georgia (ALG) website, and the two repositories, Galileo Open Learning Materials and Manifold, used to store and access open educational resources created through the grants. Participants were introduced to the grant procedures, deadlines, and templates, as well as the ALG grantees listserv. The importance of the Affordable Materials Grants page was emphasized, and the analytics of the repositories, such as most popular downloads and global usage, was discussed. The ALG website will have a mega menu, an About Us section, a grants overview, an Information Center page, and a page for creating resources. It will also have a news and events page, a data page, and a tracking spreadsheet for data. Manifold will be used for interactive materials, and there will be training resources and a student success workshop. The website is expected to be released by the end of January or early February. This meeting is a review of the projects that are being undertaken by the University of West Georgia, Clayton State, the University of North Georgia, and Georgia Gwinnett College. The University of West Georgia is transforming a fourth semester Spanish textbook to be profession/career-centered and connected to a geographical area of the Spanish speaking world. Clayton State is transforming a microbiology textbook for biology majors. The University of North Georgia is transforming a survey of chemistry course for allied health majors, and Georgia Gwinnett College is transforming an introduction to anthropology textbook. All of the projects aim to reduce the cost of textbooks for students and create engaging examples of traditional concepts. This meeting discussed an Affordable Materials Grant project at Kennesaw State University in which a new interactive textbook will be written and developed. The project will include components of simulations and instructors solutions and will replace the need to purchase traditional textbooks. The meeting also discussed grant procedures, such as service level agreements, invoices, and reports, and the funding process, which includes a statement of work, funds for personnel, professional development materials, computer hardware, and software, and 50% of the funding released at the beginning and 50% at the end. This is a meeting transcript between two parties discussing the details of a project agreement. They discuss the legal compliance, anti-discrimination clause, the ability to modify the agreement, the need for signatures from both parties, the need for the agreement to be within federal and state laws, the need for the agreement to be completed in a timely manner, the request for proposals, the statement of work, the process of getting signatures, the need for the invoice to come from the institution, and the need for a semester status report. This meeting discussed the final report for the ALG grants, which is due on December 19th. It outlined the components of the final report, such as the Word document version, data, syllabi, and photos. It also discussed upcoming reporting deadlines and the ALGGRANTEES listserv. The meeting concluded with instructions to save the Grants Information Center link and to send SLAs and invoices to Dina Anderson. This meeting was about making sure everyone had the necessary information for upcoming projects. The administrator will be out from the 16th to the 2nd, so documents should be sent to them in the meantime. The meeting concluded with a reminder to reach out with any questions and well wishes for a happy holiday break.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.9. Get Action Items from Meeting Transcript"
      ],
      "metadata": {
        "id": "MRwpgJ1gpPhL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2.9.1. Get Action Items from the Meeting Transcript one chunk at a time."
      ],
      "metadata": {
        "id": "nhZfit-nplpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"/content/drive/MyDrive/Colab Notebooks/minutes/data/Round_22_Online_Kickoff_Meeting.txt\"\n",
        "\n",
        "action_response = []\n",
        "\n",
        "chunks = break_up_file_to_chunks(filename)\n",
        "for i, chunk in enumerate(chunks):\n",
        "    prompt_request = \"Provide a list of action items with a due date from the provided meeting transcript text: \" + tokenizer.decode(chunks[i])\n",
        "\n",
        "    response = openai.Completion.create(\n",
        "            model=\"text-davinci-003\",\n",
        "            prompt=prompt_request,\n",
        "            temperature=.5,\n",
        "            max_tokens=500,\n",
        "            top_p=1,\n",
        "            frequency_penalty=0,\n",
        "            presence_penalty=0\n",
        "    )\n",
        "    \n",
        "    action_response.append(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "JvHJV8KeUzeS",
        "outputId": "f229dab2-7234-4e84-d29f-058f2c4d5eab"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (17537 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(action_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZNzPeL8SVJSG",
        "outputId": "50397550-c3ba-4632-b4d6-5d4d21c43162"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\". So if you can't make it to one of our kickoff meetings, you can always watch this one. Action Items:\\n\\n1. Introduce yourself to the ALG listserv - Due Date: Immediately \\n2. Bookmark the ALG Grants page - Due Date: Immediately \\n3. Submit a report using the ALG templates and forms - Due Date: December 19th \\n4. Convert static files into Manifold texts - Due Date: As needed \\n5. Watch the ALG Champions Welcome Training and Kickoff Training - Due Date: Immediately\", ', can you please turn on your camera?\\n\\nAction Items:\\n-Put any ancillary materials up for download (Due Date: ASAP)\\n-Help create an entirely new open textbook and get it into Manifold (Due Date: ASAP)\\n-Champions Welcome Training and Kickoff Training (Due Date: ASAP)\\n-Create Student Success Workshop (Due Date: ASAP)\\n-Work with Web Person and Marketing Coordinator to create new ALG website (Due Date: End of January/Beginning of February)\\n-Create Accessibility Guides (Due Date: ASAP)\\n-Create Open Licensing Resources (Due Date: ASAP)\\n-Create a new way to announce news and events (Due Date: ASAP)\\n-Create a Data Page (Due Date: End of January/Beginning of February)\\n-Create ALG Tracking Spreadsheet (Due Date: ASAP)\\n-Contact Project Leads Yearly for Sustainability Survey (Due Date: Ongoing)', \" to help us with this, and we're going to have them create some of the content, so we're excited about that. We're also going to be creating a lot of interactive activities and simulations, and we're going to be creating a lot of videos. We're going to be creating a lot of multimedia content, so that's our plan. And we're going to be doing this over the next two semesters, so that's what we're up to. Great. Thank you so much.\\n\\nAction Items\\n\\n1. Begin hiring process for Program Manager (January)\\n2. Create demonstration videos for laboratory techniques (by February)\\n3. Develop group work activities (by March)\\n4. Redevelop laboratory component (by April)\\n5. Create interactive activities and simulations (by May)\\n6. Create videos and multimedia content (by June)\", \" to understand, so our goal is to make it more accessible, more understandable. And so we're gonna be making a series of videos and online resources that will help them with the prerequisites, but also help them understand the material. We're also gonna be doing some experiments and bringing in some other faculty members to help us with the experiments. And then also looking at some of the data analysis and visualization, so that they can better understand the material. We're hoping to have this done by the end of the summer, so that we can have it ready for the fall semester.\\n\\nAction Items\\n\\n1. Hire students to write vignettes and case studies (Due Date: ASAP)\\n2. Develop instructional videos with annotations (Due Date: ASAP)\\n3. Rewrite and add laboratory materials (Due Date: ASAP)\\n4. Create new custom lab manuals (Due Date: Fall)\\n5. Develop comprehensive textbook-free package (Due Date: Fall)\\n6. Create materials that pass digital accessibility (Due Date: Fall)\\n7. Develop math primer, videos, and online resources (Due Date: End of Summer)\\n8. Conduct experiments and bring in faculty members to help (Due Date: End of Summer)\\n9. Analyze data and visualize material (Due Date: End of Summer)\", \" are looking at developing an online course for the junior level course in our electrical engineering department, which is basically the course on fluid mechanics. So the main goal of this project is to develop a course that's more engaging for the students and also to make sure that the students have the prerequisites to be able to take the course. So we are going to develop the course in such a way that the students can take the course and learn the material in a more engaging way. So that's the main goal of this project.\\n\\nAction Items:\\n\\n1. Contact Amy Battles and share materials - Due Date: ASAP\\n2. Create math primer with videos and online resources to get students up to speed - Due Date: 2 semesters\\n3. Make material accessible to students on different levels - Due Date: 2 semesters\\n4. Create digital textbook for Chem 1212 - Due Date: Fall 2022\\n5. Create Atlas for Histology and workbook - Due Date: TBD\\n6. Create affordable learning modules to replace textbooks - Due Date: Fall 2021\\n7. Hire student assistants for usability testing - Due Date: TBD\\n8. Review materials from Diversity and Inclusion Office - Due Date: TBD\\n9. Create OER resources for Calculus 1 - Due Date: TBD\\n10. Create problem sets and projects for Calculus 1 - Due Date: TBD\\n11. Create instructional videos for Calculus 1 - Due Date: TBD\\n12. Develop online course for Junior level Electrical Engineering course in Fluid Mechanics - Due Date: TBD\", \" the beginning and 50% at the end is also to make sure that the work is done, that the project is completed, that the work is done, and then the funds are released. So that's kind of the background of how funding works in the grant.\\n\\nAction Items:\\n\\n1. Recruit a graduate student assistant to help with the materials by August 1st \\n\\n2. Write a new textbook and use open source materials by October 1st \\n\\n3. Create instructor solutions by December 1st \\n\\n4. Replace broken links and revise by adding new text as necessary by January 1st \\n\\n5. Create PDF version of the text by February 1st \\n\\n6. Convert previously written OER for Spanish one and two into an interactive ebook with interactions embedded in the text by March 1st \\n\\n7. Update multiple choice questions, essays, and discussions by April 1st \\n\\n8. Find OER with adaptive learning software and 1st year writing by May 1st \\n\\n9. Use visualization and game development language and environment process both courses by June 1st \\n\\n10. Update grant procedures, service level agreements, invoices, and reports by July 1st\", \" breached, then there is a process that we have to go through. It's not a punitive process. It's just a process to make sure that everybody is on the same page and that we can move forward.\\n\\nAction Items: \\n1. Reach out to business and grants office to understand institutional rules and regulations - Due Date: ASAP\\n2. Ensure that the start date and end date on the service level agreement (SLA) are correct - Due Date: ASAP\\n3. Contact USG if any changes need to be made to the SLA - Due Date: ASAP\\n4. Contact USG if any issues arise that could affect the project - Due Date: ASAP\\n5. Ensure that all legal and compliance requirements for the SLA are met - Due Date: ASAP\", \" up that you're doing? Any questions about the project? Any questions about the budget? Any questions about the timeline? Any questions about the team? Any questions about the software? And if you have any questions about the SLA, that's a great place to put it.\\n\\nAction Items: \\n1. Draft SLAs and send to project leads by Monday - Due Date: Monday\\n2. Reach out to business or grants office if something looks weird - Due Date: ASAP\\n3. Once SLAs are fully executed, send to institution - Due Date: ASAP\\n4. Institution should send first invoice to USG - Due Date: ASAP\\n5. Check in every semester with semester status report - Due Date: Spring 2023\\n6. Use three digit number in notification of award and SLA - Due Date: ASAP\\n7. List team members in semester status report - Due Date: Spring 2023\\n8. Email Word document of materials to USG - Due Date: ASAP\\n9. Check in on review, adaptation, materials, course redesign, hosting, budget, timeline, team, software, and SLA - Due Date: Spring 2023\", \" this kind of stuff in the first meeting, but I think it's better if we just get it done and out of the way.\\n\\nAction Items:\\n-Send SLAs and invoices to Dina Anderson (dina.anderson@usg.edu) by December 14th (Monday)\\n-Submit final report to Grants Information Center by December 19th\\n-Submit semester status report for Spring 2023 by May 15th\\n-Submit semester status report for Summer 2023 by August 14th\\n-Submit semester status report for Fall 2023 by December 18th\", '\\n\\nAction Items: \\n1. Save the Grants Information Center link - Due Date: N/A \\n2. Karen to send an e-mail about timeline - Due Date: ASAP \\n3. Everyone to reach out whenever they have a question - Due Date: N/A \\n4. Send documents to administrator - Due Date: Between 16th and 2nd']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2.9.2. Consolidate the Meeting Transcript Action Items."
      ],
      "metadata": {
        "id": "_Od7s1fwpdy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_request = \"Consoloidate these meeting action items, but exclude action items with Due Date of Immediately: \" + str(action_response)\n",
        "\n",
        "response = openai.Completion.create(\n",
        "        model=\"text-davinci-003\",\n",
        "        prompt=prompt_request,\n",
        "        temperature=.5,\n",
        "        max_tokens=500,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "MISAIRbJWamn",
        "outputId": "01931a78-6aa1-4b6b-8b87-cf704618badb"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "meeting_action_items = response[\"choices\"][0][\"text\"]\n",
        "print(meeting_action_items)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "5b3aowAFWjdY",
        "outputId": "a1dea41d-3849-402d-d92e-2893e64cfe5e"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Consolidated Action Items:\n",
            "-Put any ancillary materials up for download (Due Date: ASAP)\n",
            "-Help create an entirely new open textbook and get it into Manifold (Due Date: ASAP)\n",
            "-Champions Welcome Training and Kickoff Training (Due Date: ASAP)\n",
            "-Create Student Success Workshop (Due Date: ASAP)\n",
            "-Work with Web Person and Marketing Coordinator to create new ALG website (Due Date: End of January/Beginning of February)\n",
            "-Create Accessibility Guides (Due Date: ASAP)\n",
            "-Create Open Licensing Resources (Due Date: ASAP)\n",
            "-Create a new way to announce news and events (Due Date: ASAP)\n",
            "-Create a Data Page (Due Date: End of January/Beginning of February)\n",
            "-Create ALG Tracking Spreadsheet (Due Date: ASAP)\n",
            "-Contact Project Leads Yearly for Sustainability Survey (Due Date: Ongoing)\n",
            "-Begin hiring process for Program Manager (January)\n",
            "-Create demonstration videos for laboratory techniques (by February)\n",
            "-Develop group work activities (by March)\n",
            "-Redevelop laboratory component (by April)\n",
            "-Create interactive activities and simulations (by May)\n",
            "-Create videos and multimedia content (by June)\n",
            "-Contact Amy Battles and share materials - Due Date: ASAP\n",
            "-Create math primer with videos and online resources to get students up to speed - Due Date: 2 semesters\n",
            "-Make material accessible to students on different levels - Due Date: 2 semesters\n",
            "-Create digital textbook for Chem 1212 - Due Date: Fall 2022\n",
            "-Create Atlas for Histology and workbook - Due Date: TBD\n",
            "-Create affordable learning modules to replace textbooks - Due Date: Fall 2021\n",
            "-Hire student assistants for usability testing - Due Date: TBD\n",
            "-Review materials from Diversity and Inclusion Office - Due Date: TBD\n",
            "-Create OER resources for Calculus 1 - Due Date: TBD\n",
            "-Create problem sets and projects for Calculus 1 - Due Date: TBD\n",
            "-Create instructional videos for Calculus 1 - Due Date: TBD\n",
            "-Develop online course for Junior level Electrical Engineering course in Fluid Mechanics - Due Date: TBD\n",
            "-Recruit a graduate student assistant to help with the materials by August 1st \n",
            "-Write a new textbook and use open source materials by October 1st \n",
            "-Create instructor solutions by December 1st \n",
            "-\n"
          ]
        }
      ]
    }
  ]
}